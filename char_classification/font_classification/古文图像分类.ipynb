{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms,models,utils\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "#from torchvision import datasets, transforms,utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关文件路径配置，在pycharm项目中将相关路径的配置都统一放在config.py中来管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\dataset\\guwen_new\\train\"\n",
    "test_path = r'C:\\dataset\\guwen_new\\test'\n",
    "data_root = r'C:\\dataset\\guwen_new'\n",
    "csv_path = r\"C:\\dataset\\guwen_new\\files\\test_infor.csv\"\n",
    "tensorboard_path=r'C:\\\\dataset\\\\guwen_new\\\\files'\n",
    "model_save_path = r'C:\\\\dataset\\\\guwen_new\\\\files\\\\dogs-vs-cats-notebook.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的创建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path:str, train=True, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.train_flag = train\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size = (224,224)),#尺寸规范\n",
    "                transforms.ToTensor(),   #转化为tensor\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self.path_list = os.listdir(data_path)\n",
    "    def __getitem__(self, idx: int):\n",
    "        # img to tensor and label to tensor\n",
    "        img_path = self.path_list[idx]\n",
    "        #print(img_path)\n",
    "        if self.train_flag is True:\n",
    "            #print(img_path.split('.'))\n",
    "            if \"Jiagu\" in img_path:\n",
    "                label = 1\n",
    "            elif \"Xiaozhuan\" in img_path:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 2\n",
    "        #print(label)\n",
    "        #else:\n",
    "        #label = int(img_path.split('.')[0]) # split 的是str类型要转换为int\n",
    "        label = torch.as_tensor(label, dtype=torch.int64) # 必须使用long 类型数据，否则后面训练会报错 expect long\n",
    "        img_path = os.path.join(self.data_path, img_path)\n",
    "        #print(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transform(img)\n",
    "        '''\n",
    "        # 将图像转换为NumPy数组\n",
    "        img_np = img.numpy()\n",
    "\n",
    "        # 将通道维度放置在最后\n",
    "        img_np = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        # 可视化图像\n",
    "        plt.imshow(img_np)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        print(img.shape)\n",
    "        '''\n",
    "        return img, label\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\dataset\\\\guwen_new\\\\train'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试一下，确保Dataset可以正常迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0043cd27914146149d6b8d1ade69b58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_ds = MyDataset(train_path)\n",
    "test_ds = MyDataset(test_path,train=False)\n",
    "for i, item in enumerate(tqdm(train_ds)):\n",
    "#     pass\n",
    "    print(item)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集划分\n",
    "实现思路是使用torch.utils.data.random_split(),来将官方提供训练数据集划分出一部分的验证集。比例是80%的训练集，20%的验证集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = train_ds\n",
    "train_size = int(0.8 * len(full_ds))\n",
    "validate_size = len(full_ds) - train_size\n",
    "new_train_ds, validate_ds = torch.utils.data.random_split(full_ds,[train_size, validate_size])#数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x26719565a90>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载\n",
    "使用torch.utils.data.DataLoader()来划分每个batch用来后面训练的时候向网络提供输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)\n",
    "## numworkers设置不为0 会报错 Broken pipe Error 网上说是win10上的pytorch bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_loader = torch.utils.data.DataLoader(new_train_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for batch_idx, data in enumerate(new_train_loader):\n",
    "    # 打印批次索引\n",
    "    print(\"Batch Index:\", batch_idx)\n",
    "    \n",
    "    # 获取批次中的输入和目标数据\n",
    "    inputs, targets = data\n",
    "    \n",
    "    # 打印每个输入样本的形状\n",
    "    print(\"Input Shapes:\", inputs.shape)\n",
    "    \n",
    "    # 打印每个目标样本的形状\n",
    "    print(\"Target Shapes:\", targets.shape)\n",
    "    \n",
    "    # 打印输入和目标数据的具体数值\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    \n",
    "    # 可以继续在此处执行其他操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载过后数据形状从三维变成四维，多的维度是batch_size，这里是32个样本构成一个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(train_loader):\n",
    "#     pass\n",
    "    print(item[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize后的图像查看\n",
    "前面提到过对数据进行了resize和正则化的处理，下面是对处理后的图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_PIL_Tensor = train_ds[1][0]\n",
    "new_img_PIL = transforms.ToPILImage()(img_PIL_Tensor).convert('RGB')\n",
    "plt.imshow(new_img_PIL)\n",
    "plt.show()\n",
    "# print(new_img_PIL.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,8,kernel_size=3,stride=1,padding=1) # 按照公式计算后经过卷积层不改变尺寸\n",
    "        self.pool = nn.MaxPool2d(2,2) # 2*2的池化 池化后size 减半\n",
    "        self.conv2 = nn.Conv2d(8,16,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(16*56*56,256)#两个池化，所以是224/2/2=56\n",
    "        self.fc2 = nn.Linear(256,64)\n",
    "        self.fc3 = nn.Linear(64,3)\n",
    "#         self.dp = nn.Dropout(p=0.5)\n",
    "    def forward(self,x):\n",
    "#         print(\"input:\", x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "#         print(\"first conv:\", x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print(\"second conv:\", x)\n",
    "             \n",
    "        x = x.view(-1, 16 * 56* 56)#将数据平整为一维的 \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))  \n",
    "        x = self.fc3(x)  \n",
    "#         x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要\n",
    "        return x\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预训练模型\n",
    "除了自己手动DIY一个网络，也可以使用Pytorch已经提供的一些性能很好的模型比如VGG16，ResNet50等等，然后微调下网络结构，来得到符合自己的任务的网络架构。还可以直接下载这些模型在ImageNet上的预训练参数，然后在自己的数据集上进行训练。\n",
    "\n",
    "我在这儿选择了ResNet50网络以及预训练好的权重进行了下实验，我在实验室的机器上面用P100跑的，因为自己的笔记本显卡太垃圾了只有2GB显存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning:\n",
      "\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning:\n",
      "\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 直接设置为True的话下载权重太慢了\n",
    "## 所以手动用浏览器下载好了之后再重新加载\n",
    "resnet50 = models.resnet152(pretrained=False)  \n",
    "model_path = r\"C:\\dataset\\guwen_new\\files\\resnet152-b121ed2d.pth\"\n",
    "resnet50.load_state_dict(torch.load(model_path))\n",
    "resnet50.fc = nn.Linear(2048, 2) #修改最后一层网络将输出调整为两维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数和优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyCNN()\n",
    "# net = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCELoss()  #二分类交叉熵损失函数\n",
    "# criterion = nn.BCEWithLogitsLoss() #二分类交叉熵损失函数 带log loss\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#也可以选择Adam优化方法\n",
    "# optimizer = torch.optim.Adam(net.parameters(),lr=1e-2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  训练日志的打印\n",
    "\n",
    "在之前的手写数字识别的准确率的计算和画图以日志的打印比较简单，在这更新为topk准确率以及使用tensorboard来画曲线。并且使用tqdm进度条来实时的打印日志。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "专门建立一个类来保存和更新准确率的结果，使用类来让代码更加的规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgrageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准确率的计算\n",
    "torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor) 返回某一维度前k个的索引\n",
    "input：一个tensor数据\n",
    "k：指明是得到前k个数据以及其index\n",
    "dim： 指定在哪个维度上排序， 默认是最后一个维度\n",
    "largest：如果为True，按照大到小排序； 如果为False，按照小到大排序\n",
    "sorted：返回的结果按照顺序返回\n",
    "out：可缺省，不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## topk的准确率计算\n",
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk) \n",
    "    batch_size = label.size(0)\n",
    "    \n",
    "    # 获取前K的索引\n",
    "    _, pred = output.topk(maxk, 1, True, True) #使用topk来获得前k个的索引\n",
    "    pred = pred.t() # 进行转置\n",
    "    # eq按照对应元素进行比较 view(1,-1) 自动转换到行为1,的形状， expand_as(pred) 扩展到pred的shape\n",
    "    # expand_as 执行按行复制来扩展，要保证列相等\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred)) # 与正确标签序列形成的矩阵相比，生成True/False矩阵\n",
    "#     print(correct)\n",
    "\n",
    "    rtn = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0) # 前k行的数据 然后平整到1维度，来计算true的总个数\n",
    "        rtn.append(correct_k.mul_(100.0 / batch_size)) # mul_() ternsor 的乘法  正确的数目/总的数目 乘以100 变成百分比\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tesnor 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "writer = SummaryWriter('C:/dataset/guwen_new/files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迭代训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def train( epochs, train_loader, device, model, criterion, optimizer,tensorboard_path):\n",
    "    model = model.to(device)\n",
    "    top1_list=[]\n",
    "    for epoch in range(epochs):\n",
    "        train_loader = tqdm(train_loader)\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        top1 = AvgrageMeter()\n",
    "        epoch_acc=[]\n",
    "        train_loader.set_description('[%s%04d/%04d %s%f]' % ('Epoch:', epoch + 1, epochs, 'lr:', 0.001))\n",
    "        for i, data in enumerate(train_loader, 0):  # 0是下标起始位置默认为0\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # 初始为0，清除上个batch的梯度信息\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs)\n",
    "            #print(labels)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #topk准确率\n",
    "            prec1, prec2 = accuracy(outputs, labels, topk=(1, 2))\n",
    "            n = inputs.size(0)\n",
    "            top1.update(prec1.item(), n)\n",
    "            train_loss += loss.item()\n",
    "            postfix = {'train_loss': '%.6f' % (train_loss / (i + 1)), 'train_acc': '%.6f' % top1.avg}\n",
    "            epoch_acc.append(top1.avg)\n",
    "            #print(top1.avg)\n",
    "            train_loader.set_postfix(log=postfix)\n",
    "            # ternsorboard 曲线绘制\n",
    "            writer = SummaryWriter(tensorboard_path)\n",
    "            writer.add_scalar('Train/Loss', loss.item(), epoch)\n",
    "            writer.add_scalar('Train/Accuracy', top1.avg, epoch)\n",
    "            writer.flush()\n",
    "        acc_epoch=np.mean(epoch_acc)\n",
    "        top1_list.append(acc_epoch)\n",
    "        print(top1)    \n",
    "    print('Finished Training')\n",
    "    return top1_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  模型评估\n",
    "准确率验证\n",
    "在验证集上面的验证，求网络的的准确率指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(validate_loader, device, model, criterion):\n",
    "    val_acc = 0.0\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # 进行评测的时候网络不更新梯度\n",
    "        val_top1 = AvgrageMeter()\n",
    "        validate_loader = tqdm(validate_loader)\n",
    "        validate_loss = 0.0\n",
    "        for i, data in enumerate(validate_loader, 0):  # 0是下标起始位置默认为0\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #         inputs,labels = data[0],data[1]\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            prec1, prec2 = accuracy(outputs, labels, topk=(1, 2))\n",
    "            n = inputs.size(0)\n",
    "            val_top1.update(prec1.item(), n)\n",
    "            validate_loss += loss.item()\n",
    "            postfix = {'validate_loss': '%.6f' % (validate_loss / (i + 1)), 'validate_acc': '%.6f' % val_top1.avg}\n",
    "            validate_loader.set_postfix(log=postfix)\n",
    "        val_acc = val_top1.avg\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出测试集的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(csv_path,test_loader, device, model):\n",
    "    result_list = []\n",
    "    model = model.to(device)\n",
    "    test_loader = tqdm(test_loader)\n",
    "    with torch.no_grad():  # 进行评测的时候网络不更新梯度\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            #print(images)\n",
    "            #print(labels)\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            softmax_func = nn.Softmax(dim=1)  # dim=1表示行的和为1\n",
    "            soft_output = softmax_func(outputs)\n",
    "            predicted = soft_output[:, 1]\n",
    "            for i in range(len(predicted)):\n",
    "                result_list.append({\n",
    "                    \"id\": labels[i].item(),\n",
    "                    \"label\": predicted[i].item()\n",
    "                })\n",
    "    # 从list转成 dataframe 然后保存为csv文件\n",
    "    columns = result_list[0].keys()\n",
    "    result_dict = {col: [anno[col] for anno in result_list] for col in columns}\n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "    result_df = result_df.sort_values(\"id\")\n",
    "    result_df.to_csv(csv_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整调用流程\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 损失函数和优化方法的确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyCNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train(epochs, train_loader, device, model, criterion, optimizer, tensorboard_path):\n",
    "    model = model.to(device)\n",
    "    top1_list = []\n",
    "    classes = ['Xiaozhuan', 'Jiagu','Jin']\n",
    "    for epoch in range(epochs):\n",
    "        train_loader = tqdm(train_loader)\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        top1 = AvgrageMeter()\n",
    "        epoch_acc = []\n",
    "        train_loader.set_description('[%s%04d/%04d %s%f]' % ('Epoch:', epoch + 1, epochs, 'lr:', 0.001))\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            prec1, prec2 = accuracy(outputs, labels, topk=(1, 2))\n",
    "            #print(prec1)\n",
    "            #print(prec2)\n",
    "            n = inputs.size(0)\n",
    "            metrics = calculate_metrics(outputs, labels)\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            #print(outputs)\n",
    "            #print(labels)\n",
    "            # Update metrics here\n",
    "              # This function should return a dictionary of metrics\n",
    "            pre = classification_report(labels.detach().cpu().numpy(), outputs.detach().cpu().numpy(), target_names=classes, digits=5)\n",
    "            print(pre)\n",
    "            top1.update(prec1.item(), n)\n",
    "            train_loss += loss.item()\n",
    "            postfix = {'train_loss': '%.6f' % (train_loss / (i + 1)), 'train_acc': '%.6f' % top1.avg}\n",
    "            epoch_acc.append(top1.avg)\n",
    "            train_loader.set_postfix(log=postfix)\n",
    "\n",
    "            writer = SummaryWriter(tensorboard_path)\n",
    "            writer.add_scalar('Train/Loss', loss.item(), epoch)\n",
    "            writer.add_scalar('Train/Accuracy', top1.avg, epoch)\n",
    "\n",
    "            # Log metrics to TensorBoard\n",
    "            for key, value in metrics.items():\n",
    "                writer.add_scalar('Train/' + key, value, epoch)\n",
    "\n",
    "            writer.flush()\n",
    "        print(metrics)\n",
    "        acc_epoch = np.mean(epoch_acc)\n",
    "        top1_list.append(acc_epoch)\n",
    "        print(top1)\n",
    "\n",
    "    print('Finished Training')\n",
    "    return top1_list\n",
    "def calculate_metrics(outputs, labels):\n",
    "    predicted_labels = outputs.argmax(dim=1)\n",
    "    correct_predictions = (predicted_labels == labels).float()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions.mean().item()\n",
    "\n",
    "    # Calculate F1 score and recall using scikit-learn\n",
    "    from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "    f1 = f1_score(labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "    recall = recall_score(labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {'Accuracy': accuracy, 'F1 Score': f1, 'Recall': recall}\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程，需要传入epoch数目，训练数据加载器，设备，网络模型，损失函数，优化方法和tensorboard画图的路径等参数。\n",
    "注意的是如果使用完整的官方训练数据集来训练网络后，用这个网络去在验证集上面验证是没有意义的，因为验证集的数据是从完整训练数据集上面划分出来，所以相当于在用训练数据验证性能。用划分过后的new_train_loader训练的网络在进行验证才有意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d400f6873740509896cc6c36561833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.76923   0.83333        13\n",
      "       Jiagu    0.60000   0.69231   0.64286        13\n",
      "         Jin    0.50000   0.50000   0.50000         6\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.66970   0.65385   0.65873        32\n",
      "weighted avg    0.70682   0.68750   0.69345        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76471   1.00000   0.86667        13\n",
      "       Jiagu    1.00000   0.75000   0.85714        12\n",
      "         Jin    1.00000   0.85714   0.92308         7\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.92157   0.86905   0.88230        32\n",
      "weighted avg    0.90441   0.87500   0.87543        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.44444   0.88889   0.59259         9\n",
      "       Jiagu    0.60000   0.40000   0.48000        15\n",
      "         Jin    0.75000   0.37500   0.50000         8\n",
      "\n",
      "    accuracy                        0.53125        32\n",
      "   macro avg    0.59815   0.55463   0.52420        32\n",
      "weighted avg    0.59375   0.53125   0.51667        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000        10\n",
      "       Jiagu    0.44444   0.66667   0.53333         6\n",
      "         Jin    1.00000   0.50000   0.66667        16\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.70370   0.72222   0.66667        32\n",
      "weighted avg    0.79167   0.68750   0.68333        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.64706   1.00000   0.78571        11\n",
      "       Jiagu    0.55556   0.83333   0.66667         6\n",
      "         Jin    1.00000   0.40000   0.57143        15\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.73420   0.74444   0.67460        32\n",
      "weighted avg    0.79534   0.68750   0.66295        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.57895   0.84615   0.68750        13\n",
      "       Jiagu    0.57143   0.44444   0.50000         9\n",
      "         Jin    0.83333   0.50000   0.62500        10\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.66124   0.59687   0.60417        32\n",
      "weighted avg    0.65633   0.62500   0.61523        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.86667   1.00000   0.92857        13\n",
      "       Jiagu    0.50000   0.71429   0.58824         7\n",
      "         Jin    1.00000   0.58333   0.73684        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78889   0.76587   0.75122        32\n",
      "weighted avg    0.83646   0.78125   0.78222        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.90909   0.86957        11\n",
      "       Jiagu    0.80000   0.80000   0.80000        10\n",
      "         Jin    0.90000   0.81818   0.85714        11\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84444   0.84242   0.84224        32\n",
      "weighted avg    0.84583   0.84375   0.84356        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.88889   0.84211         9\n",
      "       Jiagu    0.63636   0.70000   0.66667        10\n",
      "         Jin    0.90909   0.76923   0.83333        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78182   0.78604   0.78070        32\n",
      "weighted avg    0.79318   0.78125   0.78372        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.80000   0.84211        10\n",
      "       Jiagu    0.84615   0.91667   0.88000        12\n",
      "         Jin    1.00000   1.00000   1.00000        10\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91168   0.90556   0.90737        32\n",
      "weighted avg    0.90759   0.90625   0.90566        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.66667   0.72727        12\n",
      "       Jiagu    0.36364   1.00000   0.53333         4\n",
      "         Jin    0.81818   0.56250   0.66667        16\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.66061   0.74306   0.64242        32\n",
      "weighted avg    0.75455   0.65625   0.67273        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.72727   0.80000        11\n",
      "       Jiagu    0.90000   0.64286   0.75000        14\n",
      "         Jin    0.46154   0.85714   0.60000         7\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.75014   0.74242   0.71667        32\n",
      "weighted avg    0.80027   0.71875   0.73437        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.66667   0.76190        12\n",
      "       Jiagu    1.00000   0.77778   0.87500         9\n",
      "         Jin    0.68750   1.00000   0.81481        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.85880   0.81481   0.81724        32\n",
      "weighted avg    0.85091   0.81250   0.81190        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92857   0.96296        14\n",
      "       Jiagu    0.70000   0.77778   0.73684         9\n",
      "         Jin    0.66667   0.66667   0.66667         9\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.78889   0.79101   0.78882        32\n",
      "weighted avg    0.82188   0.81250   0.81603        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714         6\n",
      "       Jiagu    0.60000   0.81818   0.69231        11\n",
      "         Jin    0.88889   0.53333   0.66667        15\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.74630   0.78384   0.73871        32\n",
      "weighted avg    0.76354   0.71875   0.71120        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.46667   0.77778   0.58333         9\n",
      "       Jiagu    0.69231   0.60000   0.64286        15\n",
      "         Jin    0.50000   0.25000   0.33333         8\n",
      "\n",
      "    accuracy                        0.56250        32\n",
      "   macro avg    0.55299   0.54259   0.51984        32\n",
      "weighted avg    0.58077   0.56250   0.54874        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.76923   0.80000        13\n",
      "       Jiagu    0.55556   0.90909   0.68966        11\n",
      "         Jin    1.00000   0.25000   0.40000         8\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.79630   0.64277   0.62989        32\n",
      "weighted avg    0.77951   0.68750   0.66207        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.88889   0.76190         9\n",
      "       Jiagu    0.80000   0.75000   0.77419        16\n",
      "         Jin    0.60000   0.42857   0.50000         7\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.68889   0.68915   0.67870        32\n",
      "weighted avg    0.71875   0.71875   0.71076        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.63636   0.87500   0.73684         8\n",
      "       Jiagu    0.76923   1.00000   0.86957        10\n",
      "         Jin    0.87500   0.50000   0.63636        14\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76020   0.79167   0.74759        32\n",
      "weighted avg    0.78229   0.75000   0.73436        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.81818   0.81818        11\n",
      "       Jiagu    0.46154   0.75000   0.57143         8\n",
      "         Jin    1.00000   0.61538   0.76190        13\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.75991   0.72786   0.71717        32\n",
      "weighted avg    0.80288   0.71875   0.73363        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.93333   0.84848        15\n",
      "       Jiagu    0.85714   0.66667   0.75000         9\n",
      "         Jin    1.00000   0.87500   0.93333         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87831   0.82500   0.84394        32\n",
      "weighted avg    0.85565   0.84375   0.84200        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   0.90909   0.83333        11\n",
      "       Jiagu    0.73333   0.78571   0.75862        14\n",
      "         Jin    0.75000   0.42857   0.54545         7\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75085   0.70779   0.71247        32\n",
      "weighted avg    0.74932   0.75000   0.73767        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.81818   0.81818        11\n",
      "       Jiagu    0.61538   0.61538   0.61538        13\n",
      "         Jin    0.62500   0.62500   0.62500         8\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.68619   0.68619   0.68619        32\n",
      "weighted avg    0.68750   0.68750   0.68750        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   0.90909   0.83333        11\n",
      "       Jiagu    0.85714   0.54545   0.66667        11\n",
      "         Jin    0.66667   0.80000   0.72727        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76435   0.75152   0.74242        32\n",
      "weighted avg    0.76740   0.75000   0.74290        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.87500   0.82353         8\n",
      "       Jiagu    0.50000   0.77778   0.60870         9\n",
      "         Jin    0.77778   0.46667   0.58333        15\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.68519   0.70648   0.67185        32\n",
      "weighted avg    0.69965   0.65625   0.65052        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000         8\n",
      "       Jiagu    0.81818   0.60000   0.69231        15\n",
      "         Jin    0.77778   0.77778   0.77778         9\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75421   0.79259   0.75670        32\n",
      "weighted avg    0.76894   0.75000   0.74327        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.90909   0.76923        11\n",
      "       Jiagu    0.66667   0.44444   0.53333         9\n",
      "         Jin    0.63636   0.58333   0.60870        12\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.65657   0.64562   0.63709        32\n",
      "weighted avg    0.65530   0.65625   0.64268        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   1.00000   0.88000        11\n",
      "       Jiagu    0.90000   0.81818   0.85714        11\n",
      "         Jin    0.87500   0.70000   0.77778        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85357   0.83939   0.83831        32\n",
      "weighted avg    0.85290   0.84375   0.84020        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.81818   0.90000        11\n",
      "       Jiagu    0.46154   0.85714   0.60000         7\n",
      "         Jin    0.80000   0.57143   0.66667        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.75385   0.74892   0.72222        32\n",
      "weighted avg    0.79471   0.71875   0.73229        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.70000   0.73684        10\n",
      "       Jiagu    0.71429   0.76923   0.74074        13\n",
      "         Jin    0.55556   0.55556   0.55556         9\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.68254   0.67493   0.67771        32\n",
      "weighted avg    0.68948   0.68750   0.68744        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   0.78571   0.81481        14\n",
      "       Jiagu    0.83333   0.90909   0.86957        11\n",
      "         Jin    0.71429   0.71429   0.71429         7\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.79792   0.80303   0.79956        32\n",
      "weighted avg    0.81290   0.81250   0.81164        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.50000   1.00000   0.66667         5\n",
      "       Jiagu    0.83333   0.76923   0.80000        13\n",
      "         Jin    0.90000   0.64286   0.75000        14\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74444   0.80403   0.73889        32\n",
      "weighted avg    0.81042   0.75000   0.75729        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.90909   0.86957        11\n",
      "       Jiagu    0.54545   0.54545   0.54545        11\n",
      "         Jin    0.66667   0.60000   0.63158        10\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.68182   0.68485   0.68220        32\n",
      "weighted avg    0.68229   0.68750   0.68378        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72727   0.72727   0.72727        11\n",
      "       Jiagu    0.71429   0.90909   0.80000        11\n",
      "         Jin    0.85714   0.60000   0.70588        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76623   0.74545   0.74439        32\n",
      "weighted avg    0.76339   0.75000   0.74559        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   0.90909   0.83333        11\n",
      "       Jiagu    0.76923   0.83333   0.80000        12\n",
      "         Jin    0.83333   0.55556   0.66667         9\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79060   0.76599   0.76667        32\n",
      "weighted avg    0.78726   0.78125   0.77396        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909        10\n",
      "       Jiagu    0.81250   0.86667   0.83871        15\n",
      "         Jin    1.00000   0.57143   0.72727         7\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88194   0.81270   0.82502        32\n",
      "weighted avg    0.86003   0.84375   0.83633        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   1.00000   0.86957        10\n",
      "       Jiagu    0.70000   0.77778   0.73684         9\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78604   0.79772   0.77789        32\n",
      "weighted avg    0.79837   0.78125   0.77443        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714        12\n",
      "       Jiagu    0.66667   0.88889   0.76190         9\n",
      "         Jin    1.00000   0.36364   0.53333        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.80556   0.75084   0.71746        32\n",
      "weighted avg    0.81250   0.75000   0.71905        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.46154   0.85714   0.60000         7\n",
      "       Jiagu    0.46154   0.54545   0.50000        11\n",
      "         Jin    0.83333   0.35714   0.50000        14\n",
      "\n",
      "    accuracy                        0.53125        32\n",
      "   macro avg    0.58547   0.58658   0.53333        32\n",
      "weighted avg    0.62420   0.53125   0.52187        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.73333   0.91667   0.81481        12\n",
      "       Jiagu    0.88889   0.61538   0.72727        13\n",
      "         Jin    0.75000   0.85714   0.80000         7\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79074   0.79640   0.78070        32\n",
      "weighted avg    0.80017   0.78125   0.77601        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714        12\n",
      "       Jiagu    0.62500   0.71429   0.66667         7\n",
      "         Jin    1.00000   0.61538   0.76190        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79167   0.77656   0.76190        32\n",
      "weighted avg    0.82422   0.78125   0.77679        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.85714   0.80000         7\n",
      "       Jiagu    0.54545   0.75000   0.63158         8\n",
      "         Jin    0.84615   0.64706   0.73333        17\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.71387   0.75140   0.72164        32\n",
      "weighted avg    0.74995   0.71875   0.72248        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.44444   0.80000   0.57143         5\n",
      "       Jiagu    0.55556   0.41667   0.47619        12\n",
      "         Jin    0.78571   0.73333   0.75862        15\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.59524   0.65000   0.60208        32\n",
      "weighted avg    0.64608   0.62500   0.62346        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.76923   0.83333        13\n",
      "       Jiagu    0.81818   0.75000   0.78261        12\n",
      "         Jin    0.50000   0.71429   0.58824         7\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74242   0.74451   0.73473        32\n",
      "weighted avg    0.78551   0.75000   0.76070        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.66667   0.80000         3\n",
      "       Jiagu    1.00000   1.00000   1.00000         1\n",
      "         Jin    0.00000   0.00000   0.00000         0\n",
      "\n",
      "    accuracy                        0.75000         4\n",
      "   macro avg    0.66667   0.55556   0.60000         4\n",
      "weighted avg    1.00000   0.75000   0.85000         4\n",
      "\n",
      "{'Accuracy': 0.75, 'F1 Score': 0.6, 'Recall': 0.5555555555555555}\n",
      "<__main__.AvgrageMeter object at 0x00000266077CD730>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa21b547aa14a4498c0825ec687da2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.81818   0.85714        11\n",
      "       Jiagu    0.91667   0.73333   0.81481        15\n",
      "         Jin    0.50000   0.83333   0.62500         6\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77222   0.79495   0.76565        32\n",
      "weighted avg    0.83281   0.78125   0.79377        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   0.91667   0.84615        12\n",
      "       Jiagu    0.69231   0.64286   0.66667        14\n",
      "         Jin    0.40000   0.33333   0.36364         6\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.62601   0.63095   0.62549        32\n",
      "weighted avg    0.67253   0.68750   0.67716        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.69231   0.81818   0.75000        11\n",
      "       Jiagu    0.71429   0.83333   0.76923        12\n",
      "         Jin    1.00000   0.55556   0.71429         9\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.80220   0.73569   0.74451        32\n",
      "weighted avg    0.78709   0.75000   0.74717        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.62500   0.90909   0.74074        11\n",
      "       Jiagu    0.72727   0.88889   0.80000         9\n",
      "         Jin    0.80000   0.33333   0.47059        12\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.71742   0.71044   0.67044        32\n",
      "weighted avg    0.71939   0.68750   0.65610        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000        12\n",
      "       Jiagu    0.75000   0.64286   0.69231        14\n",
      "         Jin    1.00000   0.33333   0.50000         6\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.80556   0.65873   0.66410        32\n",
      "weighted avg    0.76562   0.71875   0.69663        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70588   0.92308   0.80000        13\n",
      "       Jiagu    0.54545   0.85714   0.66667         7\n",
      "         Jin    1.00000   0.33333   0.50000        12\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.75045   0.70452   0.65556        32\n",
      "weighted avg    0.78108   0.68750   0.65833        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714        12\n",
      "       Jiagu    0.72727   0.88889   0.80000         9\n",
      "         Jin    1.00000   0.45455   0.62500        11\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.82576   0.78114   0.76071        32\n",
      "weighted avg    0.82955   0.78125   0.76127        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889        12\n",
      "       Jiagu    1.00000   0.78571   0.88000        14\n",
      "         Jin    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93333   0.92857   0.92296        32\n",
      "weighted avg    0.92500   0.90625   0.90583        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.90000   0.85714        10\n",
      "       Jiagu    0.64286   0.81818   0.72000        11\n",
      "         Jin    0.85714   0.54545   0.66667        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.77273   0.75455   0.74794        32\n",
      "weighted avg    0.77131   0.75000   0.74452        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70588   0.92308   0.80000        13\n",
      "       Jiagu    0.87500   0.63636   0.73684        11\n",
      "         Jin    0.85714   0.75000   0.80000         8\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.81268   0.76981   0.77895        32\n",
      "weighted avg    0.80183   0.78125   0.77829        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.66667   0.74074        15\n",
      "       Jiagu    0.50000   0.66667   0.57143         9\n",
      "         Jin    0.75000   0.75000   0.75000         8\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.69444   0.69444   0.68739        32\n",
      "weighted avg    0.71875   0.68750   0.69544        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.71429   0.83333         7\n",
      "       Jiagu    0.58333   0.77778   0.66667         9\n",
      "         Jin    0.73333   0.68750   0.70968        16\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.77222   0.72652   0.73656        32\n",
      "weighted avg    0.74948   0.71875   0.72463        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.55556   0.66667         9\n",
      "       Jiagu    0.52632   0.76923   0.62500        13\n",
      "         Jin    0.57143   0.40000   0.47059        10\n",
      "\n",
      "    accuracy                        0.59375        32\n",
      "   macro avg    0.64369   0.57493   0.58742        32\n",
      "weighted avg    0.62676   0.59375   0.58847        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.50000   0.66667        14\n",
      "       Jiagu    0.60000   1.00000   0.75000         9\n",
      "         Jin    0.60000   0.66667   0.63158         9\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.73333   0.72222   0.68275        32\n",
      "weighted avg    0.77500   0.68750   0.68024        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.60000   0.66667         5\n",
      "       Jiagu    0.84615   0.91667   0.88000        12\n",
      "         Jin    0.80000   0.80000   0.80000        15\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.79872   0.77222   0.78222        32\n",
      "weighted avg    0.80950   0.81250   0.80917        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   1.00000   0.86957        10\n",
      "       Jiagu    0.85714   0.66667   0.75000         9\n",
      "         Jin    0.91667   0.84615   0.88000        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84768   0.83761   0.83319        32\n",
      "weighted avg    0.85385   0.84375   0.84018        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76471   1.00000   0.86667        13\n",
      "       Jiagu    0.66667   0.50000   0.57143         8\n",
      "         Jin    0.77778   0.63636   0.70000        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.73638   0.71212   0.71270        32\n",
      "weighted avg    0.74469   0.75000   0.73557        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.52941   1.00000   0.69231         9\n",
      "       Jiagu    0.66667   0.36364   0.47059        11\n",
      "         Jin    0.66667   0.50000   0.57143        12\n",
      "\n",
      "    accuracy                        0.59375        32\n",
      "   macro avg    0.62092   0.62121   0.57811        32\n",
      "weighted avg    0.62806   0.59375   0.57076        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.58333   1.00000   0.73684         7\n",
      "       Jiagu    0.75000   0.66667   0.70588         9\n",
      "         Jin    0.91667   0.68750   0.78571        16\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75000   0.78472   0.74281        32\n",
      "weighted avg    0.79688   0.75000   0.75257        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.61538   1.00000   0.76190         8\n",
      "       Jiagu    0.90000   0.64286   0.75000        14\n",
      "         Jin    0.66667   0.60000   0.63158        10\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.72735   0.74762   0.71449        32\n",
      "weighted avg    0.75593   0.71875   0.71597        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   1.00000   0.88000        11\n",
      "       Jiagu    0.80000   0.61538   0.69565        13\n",
      "         Jin    0.75000   0.75000   0.75000         8\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77857   0.78846   0.77522        32\n",
      "weighted avg    0.78259   0.78125   0.77261        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.85714   0.75000         7\n",
      "       Jiagu    0.71429   0.83333   0.76923        12\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75661   0.76862   0.74883        32\n",
      "weighted avg    0.77480   0.75000   0.74798        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.57143   0.66667         7\n",
      "       Jiagu    0.60000   1.00000   0.75000         9\n",
      "         Jin    0.83333   0.62500   0.71429        16\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.74444   0.73214   0.71032        32\n",
      "weighted avg    0.76042   0.71875   0.71391        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.57143   0.72727         7\n",
      "       Jiagu    0.57895   0.91667   0.70968        12\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.82261   0.70116   0.72141        32\n",
      "weighted avg    0.79697   0.71875   0.72067        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.66667   0.80000         9\n",
      "       Jiagu    0.70588   0.85714   0.77419        14\n",
      "         Jin    0.55556   0.55556   0.55556         9\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.75381   0.69312   0.70992        32\n",
      "weighted avg    0.74632   0.71875   0.71996        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.60000   0.75000        10\n",
      "       Jiagu    0.54545   0.75000   0.63158         8\n",
      "         Jin    0.73333   0.78571   0.75862        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.75960   0.71190   0.71340        32\n",
      "weighted avg    0.76970   0.71875   0.72417        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.75000   0.80000         8\n",
      "       Jiagu    0.68750   0.84615   0.75862        13\n",
      "         Jin    0.66667   0.54545   0.60000        11\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.73710   0.71387   0.71954        32\n",
      "weighted avg    0.72275   0.71875   0.71444        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.73333   0.81481        15\n",
      "       Jiagu    0.80000   0.88889   0.84211         9\n",
      "         Jin    0.70000   0.87500   0.77778         8\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80556   0.83241   0.81157        32\n",
      "weighted avg    0.82969   0.81250   0.81323        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.75000   0.81818        12\n",
      "       Jiagu    0.66667   1.00000   0.80000         4\n",
      "         Jin    0.81250   0.81250   0.81250        16\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.79306   0.85417   0.81023        32\n",
      "weighted avg    0.82708   0.81250   0.81307        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000         6\n",
      "       Jiagu    0.72727   0.61538   0.66667        13\n",
      "         Jin    0.66667   0.61538   0.64000        13\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.68687   0.74359   0.70222        32\n",
      "weighted avg    0.69129   0.68750   0.68083        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   0.84615   0.84615        13\n",
      "       Jiagu    0.62500   0.90909   0.74074        11\n",
      "         Jin    0.66667   0.25000   0.36364         8\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.71261   0.66841   0.65018        32\n",
      "weighted avg    0.72526   0.71875   0.68929        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76471   0.92857   0.83871        14\n",
      "       Jiagu    0.71429   0.45455   0.55556        11\n",
      "         Jin    0.75000   0.85714   0.80000         7\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74300   0.74675   0.73142        32\n",
      "weighted avg    0.74416   0.75000   0.73291        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.69231   1.00000   0.81818         9\n",
      "       Jiagu    0.66667   0.25000   0.36364         8\n",
      "         Jin    0.87500   0.93333   0.90323        15\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.74466   0.72778   0.69501        32\n",
      "weighted avg    0.77153   0.78125   0.74441        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.52941   0.90000   0.66667        10\n",
      "       Jiagu    0.77778   0.46667   0.58333        15\n",
      "         Jin    0.66667   0.57143   0.61538         7\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.65795   0.64603   0.62179        32\n",
      "weighted avg    0.67586   0.62500   0.61639        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000        12\n",
      "       Jiagu    0.50000   0.27273   0.35294        11\n",
      "         Jin    0.75000   0.66667   0.70588         9\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.63889   0.64646   0.61961        32\n",
      "weighted avg    0.63281   0.65625   0.61985        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.40000   1.00000   0.57143         6\n",
      "       Jiagu    0.81818   0.81818   0.81818        11\n",
      "         Jin    1.00000   0.40000   0.57143        15\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.73939   0.73939   0.65368        32\n",
      "weighted avg    0.82500   0.65625   0.65625        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   1.00000   0.95238        10\n",
      "       Jiagu    0.56250   0.90000   0.69231        10\n",
      "         Jin    1.00000   0.41667   0.58824        12\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.82386   0.77222   0.74431        32\n",
      "weighted avg    0.83487   0.75000   0.73455        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   0.92308   0.92308        13\n",
      "       Jiagu    0.27273   0.60000   0.37500         5\n",
      "         Jin    0.62500   0.35714   0.45455        14\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.60693   0.62674   0.58421        32\n",
      "weighted avg    0.69105   0.62500   0.63246        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.61538   0.69565        13\n",
      "       Jiagu    0.53333   0.80000   0.64000        10\n",
      "         Jin    0.57143   0.44444   0.50000         9\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.63492   0.61994   0.61188        32\n",
      "weighted avg    0.65238   0.62500   0.62323        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70000   0.58333   0.63636        12\n",
      "       Jiagu    0.69231   0.81818   0.75000        11\n",
      "         Jin    0.55556   0.55556   0.55556         9\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.64929   0.65236   0.64731        32\n",
      "weighted avg    0.65673   0.65625   0.65270        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.33333   0.50000        12\n",
      "       Jiagu    0.50000   0.77778   0.60870         9\n",
      "         Jin    0.64286   0.81818   0.72000        11\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.71429   0.64310   0.60957        32\n",
      "weighted avg    0.73661   0.62500   0.60620        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.50000   0.61538         8\n",
      "       Jiagu    0.56250   0.75000   0.64286        12\n",
      "         Jin    0.63636   0.58333   0.60870        12\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.66629   0.61111   0.62231        32\n",
      "weighted avg    0.64957   0.62500   0.62318        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.92308   0.88889        13\n",
      "       Jiagu    1.00000   0.81818   0.90000        11\n",
      "         Jin    0.88889   1.00000   0.94118         8\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91534   0.91375   0.91002        32\n",
      "weighted avg    0.91419   0.90625   0.90578        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92857   0.92857   0.92857        14\n",
      "       Jiagu    0.53846   0.63636   0.58333        11\n",
      "         Jin    0.40000   0.28571   0.33333         7\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.62234   0.61688   0.61508        32\n",
      "weighted avg    0.67885   0.68750   0.67969        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         2\n",
      "       Jiagu    1.00000   1.00000   1.00000         1\n",
      "         Jin    1.00000   1.00000   1.00000         1\n",
      "\n",
      "    accuracy                        1.00000         4\n",
      "   macro avg    1.00000   1.00000   1.00000         4\n",
      "weighted avg    1.00000   1.00000   1.00000         4\n",
      "\n",
      "{'Accuracy': 1.0, 'F1 Score': 1.0, 'Recall': 1.0}\n",
      "<__main__.AvgrageMeter object at 0x000002660781F6D0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe921afc017c40e5b48a3e15062e1a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72222   1.00000   0.83871        13\n",
      "       Jiagu    0.70000   0.77778   0.73684         9\n",
      "         Jin    1.00000   0.40000   0.57143        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.80741   0.72593   0.71566        32\n",
      "weighted avg    0.80278   0.75000   0.72653        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72222   1.00000   0.83871        13\n",
      "       Jiagu    0.90000   0.75000   0.81818        12\n",
      "         Jin    1.00000   0.57143   0.72727         7\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.87407   0.77381   0.79472        32\n",
      "weighted avg    0.84965   0.81250   0.80663        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.65000   1.00000   0.78788        13\n",
      "       Jiagu    0.66667   0.54545   0.60000        11\n",
      "         Jin    1.00000   0.37500   0.54545         8\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.77222   0.64015   0.64444        32\n",
      "weighted avg    0.74323   0.68750   0.66269        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.35294   0.85714   0.50000         7\n",
      "       Jiagu    0.70000   0.58333   0.63636        12\n",
      "         Jin    1.00000   0.38462   0.55556        13\n",
      "\n",
      "    accuracy                        0.56250        32\n",
      "   macro avg    0.68431   0.60836   0.56397        32\n",
      "weighted avg    0.74596   0.56250   0.57371        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714        15\n",
      "       Jiagu    1.00000   0.57143   0.72727         7\n",
      "         Jin    0.75000   0.60000   0.66667        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.83333   0.72381   0.75036        32\n",
      "weighted avg    0.80469   0.78125   0.76921        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.53846   0.87500   0.66667         8\n",
      "       Jiagu    0.75000   0.64286   0.69231        14\n",
      "         Jin    0.85714   0.60000   0.70588        10\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.71520   0.70595   0.68829        32\n",
      "weighted avg    0.73060   0.68750   0.69014        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    0.72727   0.80000   0.76190        10\n",
      "         Jin    0.77778   0.63636   0.70000        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80724   0.81212   0.80614        32\n",
      "weighted avg    0.80974   0.81250   0.80752        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.81250   0.89655        16\n",
      "       Jiagu    0.60000   0.75000   0.66667         8\n",
      "         Jin    0.55556   0.62500   0.58824         8\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.71852   0.72917   0.71715        32\n",
      "weighted avg    0.78889   0.75000   0.76200        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.90000   0.64286   0.75000        14\n",
      "         Jin    0.75000   0.90000   0.81818        10\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81667   0.84762   0.81902        32\n",
      "weighted avg    0.82812   0.81250   0.80603        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.87500   0.93333         8\n",
      "       Jiagu    0.50000   0.54545   0.52174        11\n",
      "         Jin    0.61538   0.61538   0.61538        13\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.70513   0.67861   0.69015        32\n",
      "weighted avg    0.67188   0.65625   0.66268        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.72727   0.84211        11\n",
      "       Jiagu    0.64286   1.00000   0.78261         9\n",
      "         Jin    0.80000   0.66667   0.72727        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.81429   0.79798   0.78400        32\n",
      "weighted avg    0.82455   0.78125   0.78231        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.60000   0.75000        10\n",
      "       Jiagu    0.76471   0.92857   0.83871        14\n",
      "         Jin    0.77778   0.87500   0.82353         8\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.84749   0.80119   0.80408        32\n",
      "weighted avg    0.84150   0.81250   0.80719        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.88889   0.88889         9\n",
      "       Jiagu    0.66667   1.00000   0.80000        12\n",
      "         Jin    1.00000   0.45455   0.62500        11\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.85185   0.78114   0.77130        32\n",
      "weighted avg    0.84375   0.78125   0.76484        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.88889   0.88889         9\n",
      "       Jiagu    0.73333   0.91667   0.81481        12\n",
      "         Jin    1.00000   0.72727   0.84211        11\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87407   0.84428   0.84860        32\n",
      "weighted avg    0.86875   0.84375   0.84503        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.80000   0.84211        10\n",
      "       Jiagu    0.64286   1.00000   0.78261         9\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.80688   0.80513   0.78400        32\n",
      "weighted avg    0.81969   0.78125   0.77872        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.90909   0.76923        11\n",
      "       Jiagu    0.90909   0.66667   0.76923        15\n",
      "         Jin    0.66667   0.66667   0.66667         6\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74747   0.74747   0.73504        32\n",
      "weighted avg    0.78030   0.75000   0.75000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   1.00000   0.87500         7\n",
      "       Jiagu    0.83333   0.76923   0.80000        13\n",
      "         Jin    0.81818   0.75000   0.78261        12\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80976   0.83974   0.81920        32\n",
      "weighted avg    0.81550   0.81250   0.80988        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.90909   0.86957        11\n",
      "       Jiagu    0.80000   0.92308   0.85714        13\n",
      "         Jin    1.00000   0.62500   0.76923         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87778   0.81906   0.83198        32\n",
      "weighted avg    0.86146   0.84375   0.83944        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714        12\n",
      "       Jiagu    0.58333   0.87500   0.70000         8\n",
      "         Jin    1.00000   0.33333   0.50000        12\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.77778   0.73611   0.68571        32\n",
      "weighted avg    0.80208   0.71875   0.68393        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.64286   1.00000   0.78261         9\n",
      "       Jiagu    0.66667   0.66667   0.66667        12\n",
      "         Jin    1.00000   0.54545   0.70588        11\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.76984   0.73737   0.71839        32\n",
      "weighted avg    0.77455   0.71875   0.71276        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714         9\n",
      "       Jiagu    0.84615   0.84615   0.84615        13\n",
      "         Jin    0.85714   0.60000   0.70588        10\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81777   0.81538   0.80306        32\n",
      "weighted avg    0.82254   0.81250   0.80541        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   1.00000   0.91667        11\n",
      "       Jiagu    0.76923   0.90909   0.83333        11\n",
      "         Jin    0.83333   0.50000   0.62500        10\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81624   0.80303   0.79167        32\n",
      "weighted avg    0.81571   0.81250   0.79688        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70588   0.75000   0.72727        16\n",
      "       Jiagu    0.66667   0.75000   0.70588         8\n",
      "         Jin    0.83333   0.62500   0.71429         8\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.73529   0.70833   0.71581        32\n",
      "weighted avg    0.72794   0.71875   0.71868        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.81818   0.85714        11\n",
      "       Jiagu    0.58333   0.87500   0.70000         8\n",
      "         Jin    0.90000   0.69231   0.78261        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79444   0.79516   0.77992        32\n",
      "weighted avg    0.82083   0.78125   0.78758        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.83333   0.83333         6\n",
      "       Jiagu    0.71429   0.62500   0.66667         8\n",
      "         Jin    0.89474   0.94444   0.91892        18\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.81412   0.80093   0.80631        32\n",
      "weighted avg    0.83811   0.84375   0.83981        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   1.00000   0.87500         7\n",
      "       Jiagu    0.76923   0.71429   0.74074        14\n",
      "         Jin    0.70000   0.63636   0.66667        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74900   0.78355   0.76080        32\n",
      "weighted avg    0.74730   0.75000   0.74465        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.60000   0.42857   0.50000         7\n",
      "       Jiagu    0.90909   0.66667   0.76923        15\n",
      "         Jin    0.56250   0.90000   0.69231        10\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.69053   0.66508   0.65385        32\n",
      "weighted avg    0.73317   0.68750   0.68630        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.69231   0.75000        13\n",
      "       Jiagu    0.83333   0.90909   0.86957        11\n",
      "         Jin    0.66667   0.75000   0.70588         8\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77273   0.78380   0.77515        32\n",
      "weighted avg    0.78551   0.78125   0.78007        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.76923   0.86957        13\n",
      "       Jiagu    0.54545   0.75000   0.63158         8\n",
      "         Jin    0.63636   0.63636   0.63636        11\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.72727   0.71853   0.71250        32\n",
      "weighted avg    0.76136   0.71875   0.72991        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92857   0.86667   0.89655        15\n",
      "       Jiagu    0.45455   0.83333   0.58824         6\n",
      "         Jin    0.85714   0.54545   0.66667        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74675   0.74848   0.71715        32\n",
      "weighted avg    0.81514   0.75000   0.75972        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.87500   0.82353         8\n",
      "       Jiagu    0.71429   0.90909   0.80000        11\n",
      "         Jin    0.77778   0.53846   0.63636        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75661   0.77418   0.75330        32\n",
      "weighted avg    0.75595   0.75000   0.73941        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.71429   0.90909   0.80000        11\n",
      "       Jiagu    0.80000   0.80000   0.80000        10\n",
      "         Jin    0.87500   0.63636   0.73684        11\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79643   0.78182   0.77895        32\n",
      "weighted avg    0.79632   0.78125   0.77829        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.90000   0.81818        10\n",
      "       Jiagu    0.81250   1.00000   0.89655        13\n",
      "         Jin    1.00000   0.44444   0.61538         9\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.85417   0.78148   0.77671        32\n",
      "weighted avg    0.84570   0.81250   0.79298        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.69231   0.90000   0.78261        10\n",
      "       Jiagu    0.66667   0.88889   0.76190         9\n",
      "         Jin    1.00000   0.53846   0.70000        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.78632   0.77578   0.74817        32\n",
      "weighted avg    0.81010   0.75000   0.74323        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72727   1.00000   0.84211         8\n",
      "       Jiagu    0.93333   0.87500   0.90323        16\n",
      "         Jin    1.00000   0.75000   0.85714         8\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88687   0.87500   0.86749        32\n",
      "weighted avg    0.89848   0.87500   0.87642        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    0.63636   0.63636   0.63636        11\n",
      "         Jin    0.66667   0.60000   0.63158        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.73990   0.74545   0.74149        32\n",
      "weighted avg    0.74219   0.75000   0.74492        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.57143   1.00000   0.72727         8\n",
      "       Jiagu    1.00000   0.58333   0.73684        12\n",
      "         Jin    0.90909   0.83333   0.86957        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.82684   0.80556   0.77789        32\n",
      "weighted avg    0.85877   0.78125   0.78422        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909        10\n",
      "       Jiagu    0.60000   0.85714   0.70588         7\n",
      "         Jin    0.90000   0.60000   0.72000        15\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77778   0.81905   0.77832        32\n",
      "weighted avg    0.81354   0.78125   0.77600        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70000   0.70000   0.70000        10\n",
      "       Jiagu    0.88889   0.66667   0.76190        12\n",
      "         Jin    0.69231   0.90000   0.78261        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76040   0.75556   0.74817        32\n",
      "weighted avg    0.76843   0.75000   0.74903        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.80000   0.88889        10\n",
      "       Jiagu    0.88889   0.80000   0.84211        10\n",
      "         Jin    0.73333   0.91667   0.81481        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87407   0.83889   0.84860        32\n",
      "weighted avg    0.86528   0.84375   0.84649        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.80000   0.80000        10\n",
      "       Jiagu    0.50000   0.75000   0.60000         8\n",
      "         Jin    0.90000   0.64286   0.75000        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.73333   0.73095   0.71667        32\n",
      "weighted avg    0.76875   0.71875   0.72813        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.85714   0.85714        14\n",
      "       Jiagu    0.75000   0.66667   0.70588         9\n",
      "         Jin    0.70000   0.77778   0.73684         9\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.76905   0.76720   0.76662        32\n",
      "weighted avg    0.78281   0.78125   0.78077        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.76923   0.86957        13\n",
      "       Jiagu    0.75000   0.75000   0.75000         8\n",
      "         Jin    0.64286   0.81818   0.72000        11\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79762   0.77914   0.77986        32\n",
      "weighted avg    0.81473   0.78125   0.78826        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92308   0.96000        13\n",
      "       Jiagu    0.57143   0.88889   0.69565         9\n",
      "         Jin    0.83333   0.50000   0.62500        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.80159   0.77066   0.76022        32\n",
      "weighted avg    0.82738   0.78125   0.78096        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         2\n",
      "       Jiagu    1.00000   1.00000   1.00000         1\n",
      "         Jin    1.00000   1.00000   1.00000         1\n",
      "\n",
      "    accuracy                        1.00000         4\n",
      "   macro avg    1.00000   1.00000   1.00000         4\n",
      "weighted avg    1.00000   1.00000   1.00000         4\n",
      "\n",
      "{'Accuracy': 1.0, 'F1 Score': 1.0, 'Recall': 1.0}\n",
      "<__main__.AvgrageMeter object at 0x0000026607866B50>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf167ea6852c4c6e87af7a9b8bce6c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.92308   0.88889        13\n",
      "       Jiagu    0.63636   0.87500   0.73684         8\n",
      "         Jin    1.00000   0.63636   0.77778        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.83117   0.81148   0.80117        32\n",
      "weighted avg    0.85106   0.81250   0.81268        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.68750   1.00000   0.81481        11\n",
      "       Jiagu    0.70000   0.77778   0.73684         9\n",
      "         Jin    1.00000   0.50000   0.66667        12\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.79583   0.75926   0.73944        32\n",
      "weighted avg    0.80820   0.75000   0.73733        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   1.00000   0.87500         7\n",
      "       Jiagu    0.70000   0.70000   0.70000        10\n",
      "         Jin    0.92308   0.80000   0.85714        15\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80028   0.83333   0.81071        32\n",
      "weighted avg    0.82158   0.81250   0.81194        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   1.00000   0.92308        12\n",
      "       Jiagu    0.75000   0.90000   0.81818        10\n",
      "         Jin    1.00000   0.60000   0.75000        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86905   0.83333   0.83042        32\n",
      "weighted avg    0.86830   0.84375   0.83621        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88235   1.00000   0.93750        15\n",
      "       Jiagu    0.50000   0.71429   0.58824         7\n",
      "         Jin    1.00000   0.50000   0.66667        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79412   0.73810   0.73080        32\n",
      "weighted avg    0.83548   0.78125   0.77646        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   1.00000   0.86957        10\n",
      "       Jiagu    0.80000   0.66667   0.72727         6\n",
      "         Jin    0.92857   0.81250   0.86667        16\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83260   0.82639   0.82117        32\n",
      "weighted avg    0.85467   0.84375   0.84144        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000         6\n",
      "       Jiagu    0.80000   0.57143   0.66667        14\n",
      "         Jin    0.76923   0.83333   0.80000        12\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.74530   0.80159   0.75556        32\n",
      "weighted avg    0.76346   0.75000   0.74167        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   1.00000   0.86957        10\n",
      "       Jiagu    1.00000   0.84615   0.91667        13\n",
      "         Jin    1.00000   0.88889   0.94118         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.92308   0.91168   0.90914        32\n",
      "weighted avg    0.92788   0.90625   0.90884        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.90909   0.86957        11\n",
      "       Jiagu    1.00000   0.66667   0.80000        12\n",
      "         Jin    0.75000   1.00000   0.85714         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86111   0.85859   0.84224        32\n",
      "weighted avg    0.87240   0.84375   0.83998        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.84615   0.91667        13\n",
      "       Jiagu    1.00000   0.72727   0.84211        11\n",
      "         Jin    0.61538   1.00000   0.76190         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87179   0.85781   0.84023        32\n",
      "weighted avg    0.90385   0.84375   0.85235        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    0.76923   0.90909   0.83333        11\n",
      "         Jin    0.90000   0.81818   0.85714        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88974   0.87576   0.87928        32\n",
      "weighted avg    0.88630   0.87500   0.87715        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.64286   0.75000        14\n",
      "       Jiagu    0.66667   1.00000   0.80000        12\n",
      "         Jin    0.75000   0.50000   0.60000         6\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.77222   0.71429   0.71667        32\n",
      "weighted avg    0.78438   0.75000   0.74063        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.72727   0.84211        11\n",
      "       Jiagu    0.64706   0.84615   0.73333        13\n",
      "         Jin    0.71429   0.62500   0.66667         8\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.78711   0.73281   0.74737        32\n",
      "weighted avg    0.78519   0.75000   0.75406        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.87500   0.82353         8\n",
      "       Jiagu    0.64286   0.90000   0.75000        10\n",
      "         Jin    0.88889   0.57143   0.69565        14\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76984   0.78214   0.75639        32\n",
      "weighted avg    0.78423   0.75000   0.74461        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.91667   0.95652        12\n",
      "       Jiagu    0.80000   0.88889   0.84211         9\n",
      "         Jin    0.90909   0.90909   0.90909        11\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90303   0.90488   0.90257        32\n",
      "weighted avg    0.91250   0.90625   0.90804        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.83333   0.86957        12\n",
      "       Jiagu    0.66667   0.88889   0.76190         9\n",
      "         Jin    0.88889   0.72727   0.80000        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.82155   0.81650   0.81049        32\n",
      "weighted avg    0.83396   0.81250   0.81537        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   1.00000   0.87500         7\n",
      "       Jiagu    0.62500   0.45455   0.52632        11\n",
      "         Jin    0.73333   0.78571   0.75862        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.71204   0.74675   0.71998        32\n",
      "weighted avg    0.70582   0.71875   0.70422        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714         9\n",
      "       Jiagu    0.44444   0.66667   0.53333         6\n",
      "         Jin    1.00000   0.64706   0.78571        17\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.73148   0.77124   0.72540        32\n",
      "weighted avg    0.82552   0.75000   0.75848        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.90000   0.85714        10\n",
      "       Jiagu    0.75000   0.81818   0.78261        11\n",
      "         Jin    0.88889   0.72727   0.80000        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81902   0.81515   0.81325        32\n",
      "weighted avg    0.81905   0.81250   0.81188        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   0.91667   0.84615        12\n",
      "       Jiagu    0.88889   0.72727   0.80000        11\n",
      "         Jin    0.88889   0.88889   0.88889         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85450   0.84428   0.84501        32\n",
      "weighted avg    0.85020   0.84375   0.84231        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.90000   0.85714        10\n",
      "       Jiagu    0.72727   0.72727   0.72727        11\n",
      "         Jin    0.80000   0.72727   0.76190        11\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78182   0.78485   0.78211        32\n",
      "weighted avg    0.78068   0.78125   0.77976        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.73333   1.00000   0.84615        11\n",
      "       Jiagu    0.66667   0.50000   0.57143         8\n",
      "         Jin    0.81818   0.69231   0.75000        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.73939   0.73077   0.72253        32\n",
      "weighted avg    0.75114   0.75000   0.73841        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   0.92308   0.92308        13\n",
      "       Jiagu    0.81818   0.75000   0.78261        12\n",
      "         Jin    0.75000   0.85714   0.80000         7\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83042   0.84341   0.83523        32\n",
      "weighted avg    0.84588   0.84375   0.84348        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000        10\n",
      "       Jiagu    0.50000   0.58333   0.53846        12\n",
      "         Jin    0.66667   0.20000   0.30769        10\n",
      "\n",
      "    accuracy                        0.59375        32\n",
      "   macro avg    0.61111   0.59444   0.54872        32\n",
      "weighted avg    0.60417   0.59375   0.54808        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.85714   0.80000         7\n",
      "       Jiagu    0.76923   0.90909   0.83333        11\n",
      "         Jin    0.81818   0.64286   0.72000        14\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77914   0.80303   0.78444        32\n",
      "weighted avg    0.78644   0.78125   0.77646        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.76923   0.80000        13\n",
      "       Jiagu    0.66667   0.71429   0.68966        14\n",
      "         Jin    0.60000   0.60000   0.60000         5\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.70000   0.69451   0.69655        32\n",
      "weighted avg    0.72396   0.71875   0.72047        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.83333   0.90909         6\n",
      "       Jiagu    0.75000   0.92308   0.82759        13\n",
      "         Jin    0.90909   0.76923   0.83333        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88636   0.84188   0.85667        32\n",
      "weighted avg    0.86151   0.84375   0.84520        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.66667   0.76190        12\n",
      "       Jiagu    0.66667   1.00000   0.80000        10\n",
      "         Jin    0.75000   0.60000   0.66667        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76852   0.75556   0.74286        32\n",
      "weighted avg    0.77604   0.75000   0.74405        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.90000   0.85714        10\n",
      "       Jiagu    0.72222   0.92857   0.81250        14\n",
      "         Jin    1.00000   0.37500   0.54545         8\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.84680   0.73452   0.73837        32\n",
      "weighted avg    0.82165   0.78125   0.75969        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    0.80000   1.00000   0.88889        12\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93333   0.90000   0.90838        32\n",
      "weighted avg    0.92500   0.90625   0.90716        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.80000   0.80000        15\n",
      "       Jiagu    0.50000   0.62500   0.55556         8\n",
      "         Jin    0.71429   0.55556   0.62500         9\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.67143   0.66019   0.66019        32\n",
      "weighted avg    0.70089   0.68750   0.68967        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.87500   0.93333   0.90323        15\n",
      "         Jin    1.00000   0.60000   0.75000         5\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93269   0.84444   0.87108        32\n",
      "weighted avg    0.91256   0.90625   0.90057        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.90000   0.90000        10\n",
      "       Jiagu    0.45455   0.62500   0.52632         8\n",
      "         Jin    0.81818   0.64286   0.72000        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.72424   0.72262   0.71544        32\n",
      "weighted avg    0.75284   0.71875   0.72783        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.86667   1.00000   0.92857        13\n",
      "       Jiagu    0.62500   0.83333   0.71429         6\n",
      "         Jin    1.00000   0.69231   0.81818        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83056   0.84188   0.82035        32\n",
      "weighted avg    0.87552   0.84375   0.84355        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.90909   0.90909        11\n",
      "       Jiagu    0.90000   0.81818   0.85714        11\n",
      "         Jin    0.72727   0.80000   0.76190        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84545   0.84242   0.84271        32\n",
      "weighted avg    0.84915   0.84375   0.84524        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.71429   0.76923   0.74074        13\n",
      "       Jiagu    1.00000   0.44444   0.61538         9\n",
      "         Jin    0.57143   0.80000   0.66667        10\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.76190   0.67123   0.67426        32\n",
      "weighted avg    0.75000   0.68750   0.68234        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72222   1.00000   0.83871        13\n",
      "       Jiagu    0.90000   0.64286   0.75000        14\n",
      "         Jin    0.75000   0.60000   0.66667         5\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79074   0.74762   0.75179        32\n",
      "weighted avg    0.80434   0.78125   0.77302        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.71429   0.90909   0.80000        11\n",
      "       Jiagu    1.00000   0.66667   0.80000        15\n",
      "         Jin    0.62500   0.83333   0.71429         6\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77976   0.80303   0.77143        32\n",
      "weighted avg    0.83147   0.78125   0.78393        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.90000   0.81818        10\n",
      "       Jiagu    0.60000   0.66667   0.63158         9\n",
      "         Jin    0.90000   0.69231   0.78261        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75000   0.75299   0.74412        32\n",
      "weighted avg    0.76875   0.75000   0.75125        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.85714   0.75000         7\n",
      "       Jiagu    0.66667   0.71429   0.68966        14\n",
      "         Jin    0.75000   0.54545   0.63158        11\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.69444   0.70563   0.69041        32\n",
      "weighted avg    0.69531   0.68750   0.68289        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.66667   0.66667         9\n",
      "       Jiagu    0.66667   0.80000   0.72727        15\n",
      "         Jin    0.80000   0.50000   0.61538         8\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.71111   0.65556   0.66977        32\n",
      "weighted avg    0.70000   0.68750   0.68226        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.87500   0.82353         8\n",
      "       Jiagu    0.38889   0.77778   0.51852         9\n",
      "         Jin    0.80000   0.26667   0.40000        15\n",
      "\n",
      "    accuracy                        0.56250        32\n",
      "   macro avg    0.65556   0.63981   0.58068        32\n",
      "weighted avg    0.67882   0.56250   0.53922        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   0.87500   0.87500         8\n",
      "       Jiagu    0.60000   1.00000   0.75000         9\n",
      "         Jin    1.00000   0.60000   0.75000        15\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.82500   0.82500   0.79167        32\n",
      "weighted avg    0.85625   0.78125   0.78125        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.72727   0.84211        11\n",
      "       Jiagu    0.50000   0.88889   0.64000         9\n",
      "         Jin    0.87500   0.58333   0.70000        12\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.79167   0.73316   0.72737        32\n",
      "weighted avg    0.81250   0.71875   0.73197        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         1\n",
      "       Jiagu    1.00000   1.00000   1.00000         2\n",
      "         Jin    1.00000   1.00000   1.00000         1\n",
      "\n",
      "    accuracy                        1.00000         4\n",
      "   macro avg    1.00000   1.00000   1.00000         4\n",
      "weighted avg    1.00000   1.00000   1.00000         4\n",
      "\n",
      "{'Accuracy': 1.0, 'F1 Score': 1.0, 'Recall': 1.0}\n",
      "<__main__.AvgrageMeter object at 0x00000266078B88B0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf34d090fcf4d7bb0f40fdedf047c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.66667   0.76190        12\n",
      "       Jiagu    0.66667   1.00000   0.80000         6\n",
      "         Jin    0.85714   0.85714   0.85714        14\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80423   0.84127   0.80635        32\n",
      "weighted avg    0.83333   0.81250   0.81071        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.87500   0.93333         8\n",
      "       Jiagu    1.00000   0.80000   0.88889        10\n",
      "         Jin    0.82353   1.00000   0.90323        14\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.94118   0.89167   0.90848        32\n",
      "weighted avg    0.92279   0.90625   0.90627        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.85714   0.92308         7\n",
      "       Jiagu    1.00000   0.58333   0.73684        12\n",
      "         Jin    0.68421   1.00000   0.81250        13\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.89474   0.81349   0.82414        32\n",
      "weighted avg    0.87171   0.81250   0.80832        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    0.90000   0.90000   0.90000        10\n",
      "         Jin    0.90909   0.90909   0.90909        11\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93636   0.93636   0.93636        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.75000   0.70588         8\n",
      "       Jiagu    0.80000   0.44444   0.57143         9\n",
      "         Jin    0.72222   0.86667   0.78788        15\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.72963   0.68704   0.68840        32\n",
      "weighted avg    0.73021   0.71875   0.70650        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81250   0.92857   0.86667        14\n",
      "       Jiagu    0.88889   0.66667   0.76190        12\n",
      "         Jin    0.57143   0.66667   0.61538         6\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.75761   0.75397   0.74799        32\n",
      "weighted avg    0.79594   0.78125   0.78027        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.83333   0.50000   0.62500        10\n",
      "         Jin    0.69231   0.90000   0.78261        10\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81624   0.80000   0.78920        32\n",
      "weighted avg    0.82292   0.81250   0.79988        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72727   1.00000   0.84211         8\n",
      "       Jiagu    0.81818   0.75000   0.78261        12\n",
      "         Jin    1.00000   0.83333   0.90909        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84848   0.86111   0.84460        32\n",
      "weighted avg    0.86364   0.84375   0.84491        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714         9\n",
      "       Jiagu    1.00000   0.85714   0.92308        14\n",
      "         Jin    1.00000   0.88889   0.94118         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91667   0.91534   0.90713        32\n",
      "weighted avg    0.92969   0.90625   0.90962        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   1.00000   0.86957        10\n",
      "       Jiagu    0.62500   0.62500   0.62500         8\n",
      "         Jin    1.00000   0.78571   0.88000        14\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.79808   0.80357   0.79152        32\n",
      "weighted avg    0.83413   0.81250   0.81299        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.87500   0.82353         8\n",
      "       Jiagu    0.64286   0.81818   0.72000        11\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76984   0.76952   0.75693        32\n",
      "weighted avg    0.77654   0.75000   0.74884        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.90000   0.85714        10\n",
      "       Jiagu    0.53846   0.70000   0.60870        10\n",
      "         Jin    0.75000   0.50000   0.60000        12\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.70221   0.70000   0.68861        32\n",
      "weighted avg    0.70520   0.68750   0.68307        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70000   0.87500   0.77778         8\n",
      "       Jiagu    0.80000   0.80000   0.80000        15\n",
      "         Jin    0.85714   0.66667   0.75000         9\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78571   0.78056   0.77593        32\n",
      "weighted avg    0.79107   0.78125   0.78038        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.71429   0.83333         7\n",
      "       Jiagu    0.70000   1.00000   0.82353        14\n",
      "         Jin    1.00000   0.63636   0.77778        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.90000   0.78355   0.81155        32\n",
      "weighted avg    0.86875   0.81250   0.80995        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.78571   0.84615        14\n",
      "       Jiagu    0.80000   0.72727   0.76190        11\n",
      "         Jin    0.60000   0.85714   0.70588         7\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77222   0.79004   0.77131        32\n",
      "weighted avg    0.80729   0.78125   0.78651        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.84615   0.91667        13\n",
      "       Jiagu    0.87500   0.70000   0.77778        10\n",
      "         Jin    0.69231   1.00000   0.81818         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85577   0.84872   0.83754        32\n",
      "weighted avg    0.87440   0.84375   0.84557        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.85714   0.92308         7\n",
      "       Jiagu    0.80000   0.66667   0.72727        12\n",
      "         Jin    0.75000   0.92308   0.82759        13\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.85000   0.81563   0.82598        32\n",
      "weighted avg    0.82344   0.81250   0.81086        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    0.92308   1.00000   0.96000        12\n",
      "         Jin    1.00000   0.85714   0.92308         7\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97436   0.95238   0.96103        32\n",
      "weighted avg    0.97115   0.96875   0.96817        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   1.00000   0.92308        12\n",
      "       Jiagu    0.66667   0.85714   0.75000         7\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80423   0.82418   0.80012        32\n",
      "weighted avg    0.82837   0.81250   0.80567        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.93333   0.84848        15\n",
      "       Jiagu    0.66667   0.85714   0.75000         7\n",
      "         Jin    1.00000   0.50000   0.66667        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.81481   0.76349   0.75505        32\n",
      "weighted avg    0.82292   0.78125   0.77012        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   1.00000   0.92308         6\n",
      "       Jiagu    0.63158   0.80000   0.70588        15\n",
      "         Jin    0.66667   0.36364   0.47059        11\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.71846   0.72121   0.69985        32\n",
      "weighted avg    0.68593   0.68750   0.66572        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   1.00000   0.93333         7\n",
      "       Jiagu    0.60000   0.81818   0.69231        11\n",
      "         Jin    0.77778   0.50000   0.60870        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.75093   0.77273   0.74478        32\n",
      "weighted avg    0.73793   0.71875   0.70845        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909        10\n",
      "       Jiagu    0.85714   0.92308   0.88889        13\n",
      "         Jin    1.00000   0.66667   0.80000         9\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89683   0.86325   0.86599        32\n",
      "weighted avg    0.88988   0.87500   0.87020        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   1.00000   0.95238        10\n",
      "       Jiagu    0.80000   0.66667   0.72727         6\n",
      "         Jin    0.87500   0.87500   0.87500        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86136   0.84722   0.85155        32\n",
      "weighted avg    0.87159   0.87500   0.87148        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   1.00000   0.91667        11\n",
      "       Jiagu    1.00000   0.70000   0.82353        10\n",
      "         Jin    0.83333   0.90909   0.86957        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89316   0.86970   0.86992        32\n",
      "weighted avg    0.88982   0.87500   0.87137        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   0.85714   0.88889        14\n",
      "       Jiagu    0.71429   0.90909   0.80000        11\n",
      "         Jin    0.80000   0.57143   0.66667         7\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81245   0.77922   0.78519        32\n",
      "weighted avg    0.82438   0.81250   0.80972        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.87500   0.93333         8\n",
      "       Jiagu    0.70000   0.77778   0.73684         9\n",
      "         Jin    0.86667   0.86667   0.86667        15\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85556   0.83981   0.84561        32\n",
      "weighted avg    0.85313   0.84375   0.84682        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   1.00000   0.91667        11\n",
      "       Jiagu    0.44444   0.50000   0.47059         8\n",
      "         Jin    0.80000   0.61538   0.69565        13\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.69687   0.70513   0.69430        32\n",
      "weighted avg    0.72698   0.71875   0.71536        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.81818   0.75000   0.78261        12\n",
      "         Jin    0.72727   0.66667   0.69565        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78182   0.80556   0.78905        32\n",
      "weighted avg    0.77955   0.78125   0.77657        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    0.72727   0.80000   0.76190        10\n",
      "         Jin    0.81818   0.75000   0.78261        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84848   0.85000   0.84817        32\n",
      "weighted avg    0.84659   0.84375   0.84407        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   0.85714   0.75000         7\n",
      "       Jiagu    0.84615   0.91667   0.88000        12\n",
      "         Jin    1.00000   0.76923   0.86957        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83761   0.84768   0.83319        32\n",
      "weighted avg    0.86939   0.84375   0.84732        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    0.63636   0.87500   0.73684         8\n",
      "         Jin    0.87500   0.63636   0.73684        11\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83712   0.83712   0.82456        32\n",
      "weighted avg    0.86612   0.84375   0.84375        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.76923   0.86957        13\n",
      "       Jiagu    0.78571   1.00000   0.88000        11\n",
      "         Jin    0.87500   0.87500   0.87500         8\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88690   0.88141   0.87486        32\n",
      "weighted avg    0.89509   0.87500   0.87451        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.93750   0.93750   0.93750        16\n",
      "       Jiagu    0.85714   0.75000   0.80000         8\n",
      "         Jin    0.77778   0.87500   0.82353         8\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.85747   0.85417   0.85368        32\n",
      "weighted avg    0.87748   0.87500   0.87463        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.81818   0.78261        11\n",
      "       Jiagu    0.85714   0.85714   0.85714        14\n",
      "         Jin    0.83333   0.71429   0.76923         7\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81349   0.79654   0.80299        32\n",
      "weighted avg    0.81510   0.81250   0.81229        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.90909   0.90909        11\n",
      "       Jiagu    0.75000   0.81818   0.78261        11\n",
      "         Jin    0.88889   0.80000   0.84211        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84933   0.84242   0.84460        32\n",
      "weighted avg    0.84809   0.84375   0.84468        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.73333   1.00000   0.84615        11\n",
      "       Jiagu    0.81818   0.81818   0.81818        11\n",
      "         Jin    1.00000   0.60000   0.75000        10\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.85051   0.80606   0.80478        32\n",
      "weighted avg    0.84583   0.81250   0.80649        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   0.91667   0.84615        12\n",
      "       Jiagu    0.53333   0.72727   0.61538        11\n",
      "         Jin    1.00000   0.33333   0.50000         9\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.77302   0.65909   0.65385        32\n",
      "weighted avg    0.75923   0.68750   0.66947        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.91667   0.91667        12\n",
      "       Jiagu    0.81818   0.81818   0.81818        11\n",
      "         Jin    0.77778   0.77778   0.77778         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83754   0.83754   0.83754        32\n",
      "weighted avg    0.84375   0.84375   0.84375        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    0.81818   1.00000   0.90000         9\n",
      "         Jin    1.00000   0.75000   0.85714        12\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91162   0.91667   0.90455        32\n",
      "weighted avg    0.92022   0.90625   0.90336        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        16\n",
      "       Jiagu    0.86667   1.00000   0.92857        13\n",
      "         Jin    1.00000   0.33333   0.50000         3\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.95556   0.77778   0.80952        32\n",
      "weighted avg    0.94583   0.93750   0.92411        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92857   1.00000   0.96296        13\n",
      "       Jiagu    0.88889   1.00000   0.94118         8\n",
      "         Jin    1.00000   0.81818   0.90000        11\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93915   0.93939   0.93471        32\n",
      "weighted avg    0.94320   0.93750   0.93587        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70000   0.87500   0.77778         8\n",
      "       Jiagu    0.85714   0.75000   0.80000        16\n",
      "         Jin    0.62500   0.62500   0.62500         8\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.72738   0.75000   0.73426        32\n",
      "weighted avg    0.75982   0.75000   0.75069        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.81818   0.90000        11\n",
      "       Jiagu    0.91667   0.91667   0.91667        12\n",
      "         Jin    0.81818   1.00000   0.90000         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91162   0.91162   0.90556        32\n",
      "weighted avg    0.91761   0.90625   0.90625        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         1\n",
      "       Jiagu    0.33333   1.00000   0.50000         1\n",
      "         Jin    0.00000   0.00000   0.00000         2\n",
      "\n",
      "    accuracy                        0.50000         4\n",
      "   macro avg    0.44444   0.66667   0.50000         4\n",
      "weighted avg    0.33333   0.50000   0.37500         4\n",
      "\n",
      "{'Accuracy': 0.5, 'F1 Score': 0.5, 'Recall': 0.6666666666666666}\n",
      "<__main__.AvgrageMeter object at 0x000002660790ABB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9b3cdd86ae412eae7ae60e5c9bf63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   1.00000   0.92308         6\n",
      "       Jiagu    1.00000   0.64286   0.78261        14\n",
      "         Jin    0.75000   1.00000   0.85714        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86905   0.88095   0.85428        32\n",
      "weighted avg    0.87946   0.84375   0.83690        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   1.00000   0.93333         7\n",
      "       Jiagu    0.85714   0.85714   0.85714        14\n",
      "         Jin    0.80000   0.72727   0.76190        11\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84405   0.86147   0.85079        32\n",
      "weighted avg    0.84141   0.84375   0.84107        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92857   0.96296        14\n",
      "       Jiagu    0.62500   0.83333   0.71429         6\n",
      "         Jin    0.90909   0.83333   0.86957        12\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.84470   0.86508   0.84894        32\n",
      "weighted avg    0.89560   0.87500   0.88131        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   0.92308   0.92308        13\n",
      "       Jiagu    0.77778   0.87500   0.82353         8\n",
      "         Jin    0.90000   0.81818   0.85714        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86695   0.87209   0.86792        32\n",
      "weighted avg    0.87882   0.87500   0.87553        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.84615   0.91667        13\n",
      "       Jiagu    0.60000   1.00000   0.75000         3\n",
      "         Jin    0.87500   0.87500   0.87500        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.82500   0.90705   0.84722        32\n",
      "weighted avg    0.90000   0.87500   0.88021        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.90000   0.90000        10\n",
      "       Jiagu    1.00000   0.41667   0.58824        12\n",
      "         Jin    0.58824   1.00000   0.74074        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.82941   0.77222   0.74299        32\n",
      "weighted avg    0.84007   0.75000   0.73332        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.93333   1.00000   0.96552        14\n",
      "       Jiagu    0.75000   0.85714   0.80000         7\n",
      "         Jin    0.88889   0.72727   0.80000        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.85741   0.86147   0.85517        32\n",
      "weighted avg    0.87795   0.87500   0.87241        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    1.00000   0.72727   0.84211        11\n",
      "         Jin    0.83333   1.00000   0.90909        10\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91667   0.90909   0.90257        32\n",
      "weighted avg    0.91927   0.90625   0.90237        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   1.00000   0.93333        14\n",
      "       Jiagu    0.57143   0.80000   0.66667         5\n",
      "         Jin    0.88889   0.61538   0.72727        13\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.77844   0.80513   0.77576        32\n",
      "weighted avg    0.83321   0.81250   0.80795        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   1.00000   0.88000        11\n",
      "       Jiagu    0.86667   0.86667   0.86667        15\n",
      "         Jin    0.66667   0.33333   0.44444         6\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.77302   0.73333   0.73037        32\n",
      "weighted avg    0.80134   0.81250   0.79208        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   1.00000   0.85714         9\n",
      "       Jiagu    0.78571   0.84615   0.81481        13\n",
      "         Jin    0.83333   0.50000   0.62500        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78968   0.78205   0.76565        32\n",
      "weighted avg    0.79055   0.78125   0.76740        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   1.00000   0.87500         7\n",
      "       Jiagu    0.69231   0.90000   0.78261        10\n",
      "         Jin    0.90000   0.60000   0.72000        15\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79003   0.83333   0.79254        32\n",
      "weighted avg    0.80836   0.78125   0.77347        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.77778   0.87500         9\n",
      "       Jiagu    0.65000   1.00000   0.78788        13\n",
      "         Jin    1.00000   0.50000   0.66667        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.88333   0.75926   0.77652        32\n",
      "weighted avg    0.85781   0.78125   0.77450        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.83333   0.90909        12\n",
      "       Jiagu    0.75000   0.81818   0.78261        11\n",
      "         Jin    0.70000   0.77778   0.73684         9\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81667   0.80976   0.80951        32\n",
      "weighted avg    0.82969   0.81250   0.81717        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.87500   0.93333        16\n",
      "       Jiagu    0.62500   0.62500   0.62500         8\n",
      "         Jin    0.70000   0.87500   0.77778         8\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.77500   0.79167   0.77870        32\n",
      "weighted avg    0.83125   0.81250   0.81736        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.75000   0.85714         8\n",
      "       Jiagu    0.75000   0.90000   0.81818        10\n",
      "         Jin    0.85714   0.85714   0.85714        14\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86905   0.83571   0.84416        32\n",
      "weighted avg    0.85938   0.84375   0.84497        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.90000   0.90000        10\n",
      "       Jiagu    0.88889   0.88889   0.88889         9\n",
      "         Jin    0.84615   0.84615   0.84615        13\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87835   0.87835   0.87835        32\n",
      "weighted avg    0.87500   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   1.00000   0.90000         9\n",
      "       Jiagu    0.88889   0.61538   0.72727        13\n",
      "         Jin    0.58333   0.70000   0.63636        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76347   0.77179   0.75455        32\n",
      "weighted avg    0.77352   0.75000   0.74744        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   1.00000   0.94737         9\n",
      "       Jiagu    1.00000   0.69231   0.81818        13\n",
      "         Jin    0.69231   0.90000   0.78261        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86410   0.86410   0.84939        32\n",
      "weighted avg    0.87572   0.84375   0.84340        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.69231   0.90000   0.78261        10\n",
      "       Jiagu    0.92308   0.85714   0.88889        14\n",
      "         Jin    1.00000   0.75000   0.85714         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87179   0.83571   0.84288        32\n",
      "weighted avg    0.87019   0.84375   0.84774        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.63636   1.00000   0.77778         7\n",
      "       Jiagu    0.80000   0.61538   0.69565        13\n",
      "         Jin    0.90909   0.83333   0.86957        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78182   0.81624   0.78100        32\n",
      "weighted avg    0.80511   0.78125   0.77883        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.82353   1.00000   0.90323        14\n",
      "       Jiagu    0.87500   0.70000   0.77778        10\n",
      "         Jin    0.85714   0.75000   0.80000         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85189   0.81667   0.82700        32\n",
      "weighted avg    0.84802   0.84375   0.83822        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   0.70000   0.77778        10\n",
      "       Jiagu    0.78947   0.93750   0.85714        16\n",
      "         Jin    1.00000   0.83333   0.90909         6\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88816   0.82361   0.84800        32\n",
      "weighted avg    0.85567   0.84375   0.84208        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   0.77778   0.82353         9\n",
      "       Jiagu    0.44444   0.88889   0.59259         9\n",
      "         Jin    1.00000   0.42857   0.60000        14\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.77315   0.69841   0.67204        32\n",
      "weighted avg    0.80859   0.65625   0.66078        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   1.00000   0.91667        11\n",
      "       Jiagu    0.78571   1.00000   0.88000        11\n",
      "         Jin    1.00000   0.50000   0.66667        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87729   0.83333   0.82111        32\n",
      "weighted avg    0.87345   0.84375   0.82594        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.70000   0.82353        10\n",
      "       Jiagu    0.47619   1.00000   0.64516        10\n",
      "         Jin    1.00000   0.33333   0.50000        12\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.82540   0.67778   0.65623        32\n",
      "weighted avg    0.83631   0.65625   0.64647        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.84615   0.91667        13\n",
      "       Jiagu    0.73333   1.00000   0.84615        11\n",
      "         Jin    0.83333   0.62500   0.71429         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85556   0.82372   0.82570        32\n",
      "weighted avg    0.86667   0.84375   0.84183        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.78571   0.88000        14\n",
      "       Jiagu    0.75000   1.00000   0.85714         6\n",
      "         Jin    0.84615   0.91667   0.88000        12\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86538   0.90079   0.87238        32\n",
      "weighted avg    0.89543   0.87500   0.87571        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   0.92308   0.92308        13\n",
      "       Jiagu    1.00000   0.84615   0.91667        13\n",
      "         Jin    0.75000   1.00000   0.85714         6\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.89103   0.92308   0.89896        32\n",
      "weighted avg    0.92188   0.90625   0.90811        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    1.00000   0.80000   0.88889        10\n",
      "         Jin    0.90909   1.00000   0.95238        10\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94406   0.93333   0.93376        32\n",
      "weighted avg    0.94274   0.93750   0.93540        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76471   1.00000   0.86667        13\n",
      "       Jiagu    0.60000   0.37500   0.46154         8\n",
      "         Jin    0.80000   0.72727   0.76190        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.72157   0.70076   0.69670        32\n",
      "weighted avg    0.73566   0.75000   0.72937        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    0.78571   0.78571   0.78571        14\n",
      "         Jin    0.77778   0.70000   0.73684        10\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81746   0.82857   0.82124        32\n",
      "weighted avg    0.80903   0.81250   0.80931        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81250   1.00000   0.89655        13\n",
      "       Jiagu    1.00000   0.75000   0.85714        12\n",
      "         Jin    1.00000   1.00000   1.00000         7\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93750   0.91667   0.91790        32\n",
      "weighted avg    0.92383   0.90625   0.90440        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.91667   0.91667        12\n",
      "       Jiagu    0.83333   0.83333   0.83333        12\n",
      "         Jin    0.87500   0.87500   0.87500         8\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87500   0.87500   0.87500        32\n",
      "weighted avg    0.87500   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.52941   1.00000   0.69231         9\n",
      "       Jiagu    1.00000   0.70000   0.82353        10\n",
      "         Jin    1.00000   0.61538   0.76190        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.84314   0.77179   0.75925        32\n",
      "weighted avg    0.86765   0.75000   0.76159        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.84615   0.84615   0.84615        13\n",
      "         Jin    0.88889   0.72727   0.80000        11\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84501   0.85781   0.84501        32\n",
      "weighted avg    0.84931   0.84375   0.84097        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.90000   0.81818   0.85714        11\n",
      "         Jin    0.80000   0.88889   0.84211         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90000   0.90236   0.89975        32\n",
      "weighted avg    0.90937   0.90625   0.90648        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.66667   0.76190        12\n",
      "       Jiagu    0.71429   0.71429   0.71429         7\n",
      "         Jin    0.75000   0.92308   0.82759        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78439   0.76801   0.76793        32\n",
      "weighted avg    0.79427   0.78125   0.77817        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.80000   0.88889        10\n",
      "       Jiagu    0.86667   0.81250   0.83871        16\n",
      "         Jin    0.66667   1.00000   0.80000         6\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84444   0.87083   0.84253        32\n",
      "weighted avg    0.87083   0.84375   0.84713        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.66667   0.75000         9\n",
      "       Jiagu    0.72727   0.80000   0.76190        10\n",
      "         Jin    0.78571   0.84615   0.81481        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79004   0.77094   0.77557        32\n",
      "weighted avg    0.78754   0.78125   0.78005        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    0.58333   0.77778   0.66667         9\n",
      "         Jin    0.81818   0.69231   0.75000        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.80051   0.79003   0.78801        32\n",
      "weighted avg    0.80895   0.78125   0.78824        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   0.90909   0.83333        11\n",
      "       Jiagu    0.72727   0.80000   0.76190        10\n",
      "         Jin    1.00000   0.72727   0.84211        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.83217   0.81212   0.81245        32\n",
      "weighted avg    0.83545   0.81250   0.81403        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70000   0.87500   0.77778         8\n",
      "       Jiagu    0.38462   0.71429   0.50000         7\n",
      "         Jin    0.88889   0.47059   0.61538        17\n",
      "\n",
      "    accuracy                        0.62500        32\n",
      "   macro avg    0.65783   0.68662   0.63105        32\n",
      "weighted avg    0.73136   0.62500   0.63074        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   1.00000   0.87500         7\n",
      "       Jiagu    0.75000   0.85714   0.80000        14\n",
      "         Jin    1.00000   0.63636   0.77778        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.84259   0.83117   0.81759        32\n",
      "weighted avg    0.84201   0.81250   0.80877        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.00000   0.00000   0.00000         0\n",
      "       Jiagu    0.00000   0.00000   0.00000         2\n",
      "         Jin    1.00000   1.00000   1.00000         2\n",
      "\n",
      "    accuracy                        0.50000         4\n",
      "   macro avg    0.33333   0.33333   0.33333         4\n",
      "weighted avg    0.50000   0.50000   0.50000         4\n",
      "\n",
      "{'Accuracy': 0.5, 'F1 Score': 0.3333333333333333, 'Recall': 0.3333333333333333}\n",
      "<__main__.AvgrageMeter object at 0x000002672216BC10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703954c441f54973af7ce7cd3436b6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    0.93333   1.00000   0.96552        14\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94074   0.93333   0.93186        32\n",
      "weighted avg    0.94306   0.93750   0.93549        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.71429   0.83333         7\n",
      "       Jiagu    0.64706   0.91667   0.75862        12\n",
      "         Jin    0.90000   0.69231   0.78261        13\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.84902   0.77442   0.79152        32\n",
      "weighted avg    0.82702   0.78125   0.78471        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.46154   0.63158        13\n",
      "       Jiagu    0.68750   0.91667   0.78571        12\n",
      "         Jin    0.60000   0.85714   0.70588         7\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.76250   0.74512   0.70773        32\n",
      "weighted avg    0.79531   0.71875   0.70563        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.71429   0.83333         7\n",
      "       Jiagu    0.80000   0.94118   0.86486        17\n",
      "         Jin    0.85714   0.75000   0.80000         8\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88571   0.80182   0.83273        32\n",
      "weighted avg    0.85804   0.84375   0.84175        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.81818   0.90000        11\n",
      "       Jiagu    0.71429   1.00000   0.83333        10\n",
      "         Jin    1.00000   0.81818   0.90000        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.90476   0.87879   0.87778        32\n",
      "weighted avg    0.91071   0.87500   0.87917        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.92857   0.92857   0.92857        14\n",
      "         Jin    0.80000   0.66667   0.72727         6\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.88388   0.86508   0.87195        32\n",
      "weighted avg    0.90240   0.90625   0.90261        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.90909   0.90909        11\n",
      "       Jiagu    0.52941   1.00000   0.69231         9\n",
      "         Jin    1.00000   0.33333   0.50000        12\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.81283   0.74747   0.70047        32\n",
      "weighted avg    0.83640   0.71875   0.69471        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70588   1.00000   0.82759        12\n",
      "       Jiagu    0.66667   0.88889   0.76190         9\n",
      "         Jin    1.00000   0.27273   0.42857        11\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.79085   0.72054   0.67269        32\n",
      "weighted avg    0.79596   0.71875   0.67195        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.71429   0.71429   0.71429        14\n",
      "         Jin    0.75000   0.60000   0.66667        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75476   0.77143   0.75661        32\n",
      "weighted avg    0.74687   0.75000   0.74306        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.63636   0.87500   0.73684         8\n",
      "       Jiagu    0.72727   0.66667   0.69565        12\n",
      "         Jin    1.00000   0.83333   0.90909        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78788   0.79167   0.78053        32\n",
      "weighted avg    0.80682   0.78125   0.78599        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    1.00000   0.83333   0.90909         6\n",
      "         Jin    1.00000   1.00000   1.00000        15\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97222   0.94444   0.95520        32\n",
      "weighted avg    0.97135   0.96875   0.96801        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.85714   0.92308         7\n",
      "       Jiagu    0.91667   0.84615   0.88000        13\n",
      "         Jin    0.85714   1.00000   0.92308        12\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.92460   0.90110   0.90872        32\n",
      "weighted avg    0.91257   0.90625   0.90558        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92308   0.96000        13\n",
      "       Jiagu    0.87500   0.77778   0.82353         9\n",
      "         Jin    0.83333   1.00000   0.90909        10\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90278   0.90028   0.89754        32\n",
      "weighted avg    0.91276   0.90625   0.90571        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    0.90000   0.75000   0.81818        12\n",
      "         Jin    0.76923   0.90909   0.83333        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88974   0.88636   0.88384        32\n",
      "weighted avg    0.88317   0.87500   0.87453        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    0.91667   0.84615   0.88000        13\n",
      "         Jin    0.87500   0.87500   0.87500         8\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90278   0.90705   0.90384        32\n",
      "weighted avg    0.90625   0.90625   0.90505        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.93750   0.96774        16\n",
      "       Jiagu    0.75000   0.90000   0.81818        10\n",
      "         Jin    0.80000   0.66667   0.72727         6\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.85000   0.83472   0.83773        32\n",
      "weighted avg    0.88438   0.87500   0.87592        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909        10\n",
      "       Jiagu    0.64286   0.90000   0.75000        10\n",
      "         Jin    1.00000   0.50000   0.66667        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.82540   0.80000   0.77525        32\n",
      "weighted avg    0.83631   0.78125   0.76847        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92308   0.96000        13\n",
      "       Jiagu    0.33333   1.00000   0.50000         4\n",
      "         Jin    1.00000   0.53333   0.69565        15\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.77778   0.81880   0.71855        32\n",
      "weighted avg    0.91667   0.75000   0.77859        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   1.00000   0.94737         9\n",
      "       Jiagu    0.66667   0.90909   0.76923        11\n",
      "         Jin    1.00000   0.58333   0.73684        12\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.85556   0.83081   0.81781        32\n",
      "weighted avg    0.85729   0.81250   0.80719        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.90000   0.90000        10\n",
      "       Jiagu    0.78571   0.91667   0.84615        12\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89524   0.87222   0.87835        32\n",
      "weighted avg    0.88839   0.87500   0.87634        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.90909   0.86957        11\n",
      "       Jiagu    0.88889   0.72727   0.80000        11\n",
      "         Jin    0.90909   1.00000   0.95238        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87710   0.87879   0.87398        32\n",
      "weighted avg    0.87610   0.87500   0.87153        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    1.00000   0.80000   0.88889        10\n",
      "         Jin    0.86667   1.00000   0.92857        13\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.95556   0.93333   0.93915        32\n",
      "weighted avg    0.94583   0.93750   0.93626        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.71429   0.50000   0.58824        10\n",
      "         Jin    0.66667   0.80000   0.72727        10\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.76801   0.76667   0.75850        32\n",
      "weighted avg    0.77770   0.78125   0.77110        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.90000   0.69231   0.78261        13\n",
      "         Jin    0.75000   0.81818   0.78261        11\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81667   0.83683   0.81804        32\n",
      "weighted avg    0.82344   0.81250   0.80918        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.71429   1.00000   0.83333        10\n",
      "       Jiagu    0.87500   0.63636   0.73684        11\n",
      "         Jin    0.80000   0.72727   0.76190        11\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.79643   0.78788   0.77736        32\n",
      "weighted avg    0.79900   0.78125   0.77561        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   1.00000   0.94737         9\n",
      "       Jiagu    0.72727   0.80000   0.76190        10\n",
      "         Jin    0.90909   0.76923   0.83333        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84545   0.85641   0.84754        32\n",
      "weighted avg    0.84972   0.84375   0.84308        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         7\n",
      "       Jiagu    0.53846   0.77778   0.63636         9\n",
      "         Jin    0.83333   0.62500   0.71429        16\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.79060   0.80093   0.78355        32\n",
      "weighted avg    0.78686   0.75000   0.75487        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    0.81818   0.90000   0.85714        10\n",
      "         Jin    0.91667   0.84615   0.88000        13\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91162   0.91538   0.91238        32\n",
      "weighted avg    0.90933   0.90625   0.90661        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.77778   0.63636   0.70000        11\n",
      "       Jiagu    0.43750   0.87500   0.58333         8\n",
      "         Jin    1.00000   0.53846   0.70000        13\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.73843   0.68328   0.66111        32\n",
      "weighted avg    0.78299   0.65625   0.67083        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.94444   1.00000   0.97143        17\n",
      "       Jiagu    0.87500   0.77778   0.82353         9\n",
      "         Jin    0.83333   0.83333   0.83333         6\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.88426   0.87037   0.87610        32\n",
      "weighted avg    0.90408   0.90625   0.90394        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.75000   0.85714        12\n",
      "       Jiagu    0.88889   0.88889   0.88889         9\n",
      "         Jin    0.78571   1.00000   0.88000        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89153   0.87963   0.87534        32\n",
      "weighted avg    0.89509   0.87500   0.87393        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90909   0.95238        11\n",
      "       Jiagu    0.81818   0.69231   0.75000        13\n",
      "         Jin    0.54545   0.75000   0.63158         8\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78788   0.78380   0.77799        32\n",
      "weighted avg    0.81250   0.78125   0.78996        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    0.85714   1.00000   0.92308         6\n",
      "         Jin    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.95238   0.97222   0.95987        32\n",
      "weighted avg    0.97321   0.96875   0.96927        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    0.90000   1.00000   0.94737         9\n",
      "         Jin    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96667   0.97222   0.96796        32\n",
      "weighted avg    0.97188   0.96875   0.96889        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   0.81818   0.81818        11\n",
      "       Jiagu    0.76923   0.71429   0.74074        14\n",
      "         Jin    0.75000   0.85714   0.80000         7\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.77914   0.79654   0.78631        32\n",
      "weighted avg    0.78185   0.78125   0.78032        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.73684   0.93333   0.82353        15\n",
      "       Jiagu    0.83333   0.62500   0.71429         8\n",
      "         Jin    0.85714   0.66667   0.75000         9\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.80911   0.74167   0.76261        32\n",
      "weighted avg    0.79480   0.78125   0.77554        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.61538   1.00000   0.76190         8\n",
      "       Jiagu    0.80000   0.61538   0.69565        13\n",
      "         Jin    0.88889   0.72727   0.80000        11\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76809   0.78089   0.75252        32\n",
      "weighted avg    0.78440   0.75000   0.74808        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    0.84615   1.00000   0.91667        11\n",
      "         Jin    1.00000   0.83333   0.90909        12\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94872   0.94444   0.94192        32\n",
      "weighted avg    0.94712   0.93750   0.93726        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.76923   0.83333        13\n",
      "       Jiagu    0.80000   0.85714   0.82759        14\n",
      "         Jin    0.83333   1.00000   0.90909         5\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84747   0.87546   0.85667        32\n",
      "weighted avg    0.84953   0.84375   0.84266        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.90909   0.90909        11\n",
      "       Jiagu    1.00000   0.87500   0.93333         8\n",
      "         Jin    0.85714   0.92308   0.88889        13\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.92208   0.90239   0.91044        32\n",
      "weighted avg    0.91071   0.90625   0.90694        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.75000   0.80000         8\n",
      "       Jiagu    0.70588   0.85714   0.77419        14\n",
      "         Jin    0.75000   0.60000   0.66667        10\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.77101   0.73571   0.74695        32\n",
      "weighted avg    0.75748   0.75000   0.74704        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92857   0.96296        14\n",
      "       Jiagu    0.75000   1.00000   0.85714         9\n",
      "         Jin    1.00000   0.77778   0.87500         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91667   0.90212   0.89837        32\n",
      "weighted avg    0.92969   0.90625   0.90846        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   0.91667   0.84615        12\n",
      "       Jiagu    0.71429   0.90909   0.80000        11\n",
      "         Jin    0.75000   0.33333   0.46154         9\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75000   0.71970   0.70256        32\n",
      "weighted avg    0.75112   0.75000   0.72212        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.72727   1.00000   0.84211         8\n",
      "       Jiagu    0.77778   0.77778   0.77778         9\n",
      "         Jin    0.91667   0.73333   0.81481        15\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80724   0.83704   0.81157        32\n",
      "weighted avg    0.83026   0.81250   0.81122        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.50000   1.00000   0.66667         1\n",
      "       Jiagu    0.00000   0.00000   0.00000         1\n",
      "         Jin    1.00000   0.50000   0.66667         2\n",
      "\n",
      "    accuracy                        0.50000         4\n",
      "   macro avg    0.50000   0.50000   0.44444         4\n",
      "weighted avg    0.62500   0.50000   0.50000         4\n",
      "\n",
      "{'Accuracy': 0.5, 'F1 Score': 0.4444444444444444, 'Recall': 0.5}\n",
      "<__main__.AvgrageMeter object at 0x00000267221BFB80>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabb8c9a0228408d80374c56cbd4ea03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.93333   0.96552        15\n",
      "       Jiagu    0.90000   0.90000   0.90000        10\n",
      "         Jin    0.87500   1.00000   0.93333         7\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.92500   0.94444   0.93295        32\n",
      "weighted avg    0.94141   0.93750   0.93800        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90909   0.95238        11\n",
      "       Jiagu    0.88889   0.80000   0.84211        10\n",
      "         Jin    0.84615   1.00000   0.91667        11\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91168   0.90303   0.90372        32\n",
      "weighted avg    0.91239   0.90625   0.90564        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90909   0.95238        11\n",
      "       Jiagu    0.66667   0.85714   0.75000         7\n",
      "         Jin    0.84615   0.78571   0.81481        14\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83761   0.85065   0.83907        32\n",
      "weighted avg    0.85978   0.84375   0.84792        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    1.00000   0.55556   0.71429         9\n",
      "         Jin    0.69231   1.00000   0.81818         9\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89744   0.85185   0.84416        32\n",
      "weighted avg    0.91346   0.87500   0.86851        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   1.00000   0.95238        10\n",
      "       Jiagu    0.85714   0.85714   0.85714        14\n",
      "         Jin    0.85714   0.75000   0.80000         8\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87446   0.86905   0.86984        32\n",
      "weighted avg    0.87338   0.87500   0.87262        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    1.00000   0.90909   0.95238        11\n",
      "         Jin    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97436   0.96970   0.97079        32\n",
      "weighted avg    0.97115   0.96875   0.96863        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.88889   0.88889         9\n",
      "       Jiagu    0.76923   1.00000   0.86957        10\n",
      "         Jin    1.00000   0.76923   0.86957        13\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88604   0.88604   0.87601        32\n",
      "weighted avg    0.89663   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90000   0.90000   0.90000        10\n",
      "       Jiagu    0.80000   0.92308   0.85714        13\n",
      "         Jin    0.85714   0.66667   0.75000         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85238   0.82991   0.83571        32\n",
      "weighted avg    0.84732   0.84375   0.84040        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92857   1.00000   0.96296        13\n",
      "       Jiagu    0.92857   0.92857   0.92857        14\n",
      "         Jin    1.00000   0.80000   0.88889         5\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.95238   0.90952   0.92681        32\n",
      "weighted avg    0.93973   0.93750   0.93634        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.86667   1.00000   0.92857        13\n",
      "       Jiagu    1.00000   0.90909   0.95238        11\n",
      "         Jin    1.00000   0.87500   0.93333         8\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.95556   0.92803   0.93810        32\n",
      "weighted avg    0.94583   0.93750   0.93795        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    0.91667   0.91667   0.91667        12\n",
      "         Jin    0.90909   0.83333   0.86957        12\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90488   0.91667   0.90914        32\n",
      "weighted avg    0.90688   0.90625   0.90513        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.66667   1.00000   0.80000         8\n",
      "       Jiagu    0.63636   0.70000   0.66667        10\n",
      "         Jin    1.00000   0.64286   0.78261        14\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76768   0.78095   0.74976        32\n",
      "weighted avg    0.80303   0.75000   0.75072        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.62500   1.00000   0.76923         5\n",
      "         Jin    1.00000   0.80000   0.88889        15\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.87500   0.93333   0.88604        32\n",
      "weighted avg    0.94141   0.90625   0.91186        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.50000   0.66667         4\n",
      "       Jiagu    0.85714   0.63158   0.72727        19\n",
      "         Jin    0.50000   0.88889   0.64000         9\n",
      "\n",
      "    accuracy                        0.68750        32\n",
      "   macro avg    0.78571   0.67349   0.67798        32\n",
      "weighted avg    0.77455   0.68750   0.69515        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.90909   0.90909   0.90909        11\n",
      "       Jiagu    0.92308   0.92308   0.92308        13\n",
      "         Jin    0.75000   0.75000   0.75000         8\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86072   0.86072   0.86072        32\n",
      "weighted avg    0.87500   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.87500   0.93333        16\n",
      "       Jiagu    0.81818   0.90000   0.85714        10\n",
      "         Jin    0.85714   1.00000   0.92308         6\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.89177   0.92500   0.90452        32\n",
      "weighted avg    0.91640   0.90625   0.90760        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.80000   0.88889        15\n",
      "       Jiagu    0.60000   1.00000   0.75000         6\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86667   0.90303   0.86376        32\n",
      "weighted avg    0.92500   0.87500   0.88467        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.85714   0.85714   0.85714         7\n",
      "       Jiagu    0.86667   1.00000   0.92857        13\n",
      "         Jin    1.00000   0.83333   0.90909        12\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90794   0.89683   0.89827        32\n",
      "weighted avg    0.91458   0.90625   0.90564        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    1.00000   0.90909   0.95238        11\n",
      "         Jin    1.00000   1.00000   1.00000        13\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96296   0.96970   0.96452        32\n",
      "weighted avg    0.97222   0.96875   0.96893        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.76923   0.90909   0.83333        11\n",
      "         Jin    1.00000   0.69231   0.81818        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85641   0.86713   0.84680        32\n",
      "weighted avg    0.87067   0.84375   0.84107        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   0.92308   0.85714        13\n",
      "       Jiagu    0.88889   0.88889   0.88889         9\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89630   0.87066   0.87831        32\n",
      "weighted avg    0.88750   0.87500   0.87599        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.66667   0.85714   0.75000         7\n",
      "         Jin    1.00000   0.76923   0.86957        13\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86325   0.87546   0.85986        32\n",
      "weighted avg    0.89824   0.87500   0.87732        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.93750   0.88235        16\n",
      "       Jiagu    1.00000   0.57143   0.72727         7\n",
      "         Jin    0.80000   0.88889   0.84211         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87778   0.79927   0.81724        32\n",
      "weighted avg    0.86042   0.84375   0.83711        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.88889   0.88889         9\n",
      "       Jiagu    0.91667   0.78571   0.84615        14\n",
      "         Jin    0.81818   1.00000   0.90000         9\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87458   0.89153   0.87835        32\n",
      "weighted avg    0.88116   0.87500   0.87332        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.91667   0.95652        12\n",
      "       Jiagu    1.00000   0.60000   0.75000        10\n",
      "         Jin    0.66667   1.00000   0.80000        10\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88889   0.83889   0.83551        32\n",
      "weighted avg    0.89583   0.84375   0.84307        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.91667   0.91667        12\n",
      "       Jiagu    0.44444   0.66667   0.53333         6\n",
      "         Jin    0.72727   0.57143   0.64000        14\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.69613   0.71825   0.69667        32\n",
      "weighted avg    0.74527   0.71875   0.72375        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   0.92308   0.92308        13\n",
      "       Jiagu    1.00000   1.00000   1.00000        10\n",
      "         Jin    0.88889   0.88889   0.88889         9\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93732   0.93732   0.93732        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    0.78571   1.00000   0.88000        11\n",
      "         Jin    1.00000   0.76923   0.86957        13\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.92857   0.92308   0.91652        32\n",
      "weighted avg    0.92634   0.90625   0.90576        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    1.00000   1.00000   1.00000        11\n",
      "         Jin    1.00000   1.00000   1.00000        10\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   0.91667   0.88000        12\n",
      "       Jiagu    0.86667   0.92857   0.89655        14\n",
      "         Jin    1.00000   0.66667   0.80000         6\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.90427   0.83730   0.85885        32\n",
      "weighted avg    0.88397   0.87500   0.87224        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    0.84615   1.00000   0.91667        11\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94872   0.93636   0.93881        32\n",
      "weighted avg    0.94712   0.93750   0.93854        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    1.00000   0.92857   0.96296        14\n",
      "         Jin    0.83333   1.00000   0.90909         5\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.94444   0.97619   0.95735        32\n",
      "weighted avg    0.97396   0.96875   0.96959        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    0.69231   0.90000   0.78261        10\n",
      "         Jin    0.90000   0.75000   0.81818        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86410   0.85000   0.84939        32\n",
      "weighted avg    0.86635   0.84375   0.84744        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.78571   0.91667   0.84615        12\n",
      "       Jiagu    0.81818   0.81818   0.81818        11\n",
      "         Jin    1.00000   0.77778   0.87500         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86797   0.83754   0.84645        32\n",
      "weighted avg    0.85714   0.84375   0.84465        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        16\n",
      "       Jiagu    1.00000   0.76923   0.86957        13\n",
      "         Jin    0.50000   1.00000   0.66667         3\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.83333   0.92308   0.84541        32\n",
      "weighted avg    0.95312   0.90625   0.91576        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.70000   1.00000   0.82353         7\n",
      "       Jiagu    0.81818   0.75000   0.78261        12\n",
      "         Jin    0.90909   0.76923   0.83333        13\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.80909   0.83974   0.81316        32\n",
      "weighted avg    0.82926   0.81250   0.81217        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.86667   1.00000   0.92857        13\n",
      "       Jiagu    0.84615   0.91667   0.88000        12\n",
      "         Jin    0.75000   0.42857   0.54545         7\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.82094   0.78175   0.78468        32\n",
      "weighted avg    0.83345   0.84375   0.82655        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909         5\n",
      "       Jiagu    0.68750   0.84615   0.75862        13\n",
      "         Jin    0.90000   0.64286   0.75000        14\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.80694   0.82967   0.80590        32\n",
      "weighted avg    0.80326   0.78125   0.77836        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    0.76923   0.90909   0.83333        11\n",
      "         Jin    0.90000   0.81818   0.85714        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88974   0.87576   0.87928        32\n",
      "weighted avg    0.88630   0.87500   0.87715        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   1.00000   0.93333         7\n",
      "       Jiagu    0.90000   0.90000   0.90000        10\n",
      "         Jin    0.92857   0.86667   0.89655        15\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90119   0.92222   0.90996        32\n",
      "weighted avg    0.90792   0.90625   0.90568        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   0.70000   0.77778        10\n",
      "       Jiagu    0.55556   0.71429   0.62500         7\n",
      "         Jin    0.93333   0.93333   0.93333        15\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.78796   0.78254   0.77870        32\n",
      "weighted avg    0.83247   0.81250   0.81727        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    0.71429   0.55556   0.62500         9\n",
      "         Jin    0.75000   0.85714   0.80000        14\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.82143   0.80423   0.80833        32\n",
      "weighted avg    0.81027   0.81250   0.80703        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   0.88889   0.88889         9\n",
      "       Jiagu    0.80000   0.80000   0.80000        10\n",
      "         Jin    0.92308   0.92308   0.92308        13\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87066   0.87066   0.87066        32\n",
      "weighted avg    0.87500   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909         5\n",
      "       Jiagu    0.90909   0.90909   0.90909        11\n",
      "         Jin    0.93333   0.87500   0.90323        16\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.89192   0.92803   0.90714        32\n",
      "weighted avg    0.90938   0.90625   0.90616        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         1\n",
      "       Jiagu    0.33333   1.00000   0.50000         1\n",
      "         Jin    0.00000   0.00000   0.00000         2\n",
      "\n",
      "    accuracy                        0.50000         4\n",
      "   macro avg    0.44444   0.66667   0.50000         4\n",
      "weighted avg    0.33333   0.50000   0.37500         4\n",
      "\n",
      "{'Accuracy': 0.5, 'F1 Score': 0.5, 'Recall': 0.6666666666666666}\n",
      "<__main__.AvgrageMeter object at 0x0000026723FA5850>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65a70bd667944a68455fd4f3df3af8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.72727   0.88889   0.80000         9\n",
      "         Jin    0.88889   0.72727   0.80000        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87205   0.87205   0.86667        32\n",
      "weighted avg    0.88510   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889        12\n",
      "       Jiagu    1.00000   0.71429   0.83333         7\n",
      "         Jin    0.91667   0.84615   0.88000        13\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.90556   0.85348   0.86741        32\n",
      "weighted avg    0.89115   0.87500   0.87312        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    1.00000   0.80000   0.88889        10\n",
      "         Jin    0.87500   1.00000   0.93333        14\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.95833   0.93333   0.94074        32\n",
      "weighted avg    0.94531   0.93750   0.93611        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.93333   1.00000   0.96552        14\n",
      "       Jiagu    1.00000   0.80000   0.88889        10\n",
      "         Jin    0.88889   1.00000   0.94118         8\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94074   0.93333   0.93186        32\n",
      "weighted avg    0.94306   0.93750   0.93549        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    1.00000   0.70000   0.82353        10\n",
      "         Jin    0.75000   1.00000   0.85714         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91667   0.90000   0.89356        32\n",
      "weighted avg    0.92969   0.90625   0.90467        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    1.00000   0.90909   0.95238        11\n",
      "         Jin    0.91667   1.00000   0.95652        11\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97222   0.96970   0.96963        32\n",
      "weighted avg    0.97135   0.96875   0.96869        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    1.00000   1.00000   1.00000        13\n",
      "         Jin    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    1.00000   1.00000   1.00000        10\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97222   0.96970   0.96963        32\n",
      "weighted avg    0.97135   0.96875   0.96869        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    0.88889   1.00000   0.94118         8\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96296   0.96970   0.96452        32\n",
      "weighted avg    0.97222   0.96875   0.96893        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.75000   0.37500   0.50000         8\n",
      "       Jiagu    0.61111   1.00000   0.75862        11\n",
      "         Jin    1.00000   0.76923   0.86957        13\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.78704   0.71474   0.70940        32\n",
      "weighted avg    0.80382   0.75000   0.73904        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         3\n",
      "       Jiagu    0.83333   1.00000   0.90909        15\n",
      "         Jin    1.00000   0.78571   0.88000        14\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.94444   0.92857   0.92970        32\n",
      "weighted avg    0.92188   0.90625   0.90489        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    0.63636   0.87500   0.73684         8\n",
      "         Jin    0.87500   0.63636   0.73684        11\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83712   0.83712   0.82456        32\n",
      "weighted avg    0.86612   0.84375   0.84375        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90909   0.95238        11\n",
      "       Jiagu    0.83333   0.83333   0.83333        12\n",
      "         Jin    0.70000   0.77778   0.73684         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84444   0.84007   0.84085        32\n",
      "weighted avg    0.85313   0.84375   0.84712        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.72727   0.84211        11\n",
      "       Jiagu    1.00000   0.76923   0.86957        13\n",
      "         Jin    0.57143   1.00000   0.72727         8\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.85714   0.83217   0.81298        32\n",
      "weighted avg    0.89286   0.81250   0.82455        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    0.90909   1.00000   0.95238        10\n",
      "         Jin    1.00000   0.85714   0.92308        14\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93266   0.95238   0.93888        32\n",
      "weighted avg    0.94381   0.93750   0.93676        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    1.00000   1.00000   1.00000         4\n",
      "         Jin    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    0.89474   0.94444   0.91892        18\n",
      "         Jin    1.00000   0.66667   0.80000         6\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.92788   0.87037   0.88670        32\n",
      "weighted avg    0.91301   0.90625   0.90219        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    0.62500   1.00000   0.76923        10\n",
      "         Jin    1.00000   0.50000   0.66667        12\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.87500   0.83333   0.81197        32\n",
      "weighted avg    0.88281   0.81250   0.80288        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   0.83333   0.83333        12\n",
      "       Jiagu    0.66667   0.75000   0.70588         8\n",
      "         Jin    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.83333   0.83333   0.83191        32\n",
      "weighted avg    0.85417   0.84375   0.84767        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    1.00000   1.00000   1.00000        11\n",
      "         Jin    1.00000   1.00000   1.00000        13\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    0.92857   1.00000   0.96296        13\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97619   0.96970   0.97178        32\n",
      "weighted avg    0.97098   0.96875   0.96858        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         4\n",
      "       Jiagu    0.92308   0.85714   0.88889        14\n",
      "         Jin    0.85714   0.85714   0.85714        14\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86007   0.90476   0.87831        32\n",
      "weighted avg    0.87885   0.87500   0.87500        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    1.00000   0.81818   0.90000        11\n",
      "         Jin    0.83333   1.00000   0.90909        10\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94444   0.93939   0.93636        32\n",
      "weighted avg    0.94792   0.93750   0.93722        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.80000   0.80000   0.80000        10\n",
      "         Jin    0.88889   0.80000   0.84211        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87066   0.86667   0.86737        32\n",
      "weighted avg    0.87393   0.87500   0.87316        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    0.81250   1.00000   0.89655        13\n",
      "         Jin    1.00000   0.70000   0.82353        10\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93750   0.90000   0.90669        32\n",
      "weighted avg    0.92383   0.90625   0.90283        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    0.90000   1.00000   0.94737         9\n",
      "         Jin    1.00000   0.88889   0.94118         9\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96667   0.96296   0.96285        32\n",
      "weighted avg    0.97188   0.96875   0.96865        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    0.88889   1.00000   0.94118         8\n",
      "         Jin    1.00000   0.90000   0.94737        10\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96296   0.96667   0.96285        32\n",
      "weighted avg    0.97222   0.96875   0.96885        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         6\n",
      "       Jiagu    0.81250   0.92857   0.86667        14\n",
      "         Jin    0.90000   0.75000   0.81818        12\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.90417   0.89286   0.89495        32\n",
      "weighted avg    0.88047   0.87500   0.87348        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.88889   0.94118         9\n",
      "       Jiagu    0.90909   1.00000   0.95238        10\n",
      "         Jin    0.92308   0.92308   0.92308        13\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94406   0.93732   0.93888        32\n",
      "weighted avg    0.94034   0.93750   0.93732        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    1.00000   0.69231   0.81818        13\n",
      "         Jin    0.70000   1.00000   0.82353         7\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87436   0.89744   0.86724        32\n",
      "weighted avg    0.90553   0.87500   0.87253        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.87500   1.00000   0.93333         7\n",
      "       Jiagu    0.88889   0.66667   0.76190        12\n",
      "         Jin    0.80000   0.92308   0.85714        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85463   0.86325   0.85079        32\n",
      "weighted avg    0.84974   0.84375   0.83810        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.76923   1.00000   0.86957        10\n",
      "       Jiagu    1.00000   0.66667   0.80000        12\n",
      "         Jin    0.90909   1.00000   0.95238        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89277   0.88889   0.87398        32\n",
      "weighted avg    0.89948   0.87500   0.86936        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.92308   1.00000   0.96000        12\n",
      "       Jiagu    0.81818   0.90000   0.85714        10\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91375   0.90000   0.90201        32\n",
      "weighted avg    0.91434   0.90625   0.90563        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.94118   0.96970        17\n",
      "       Jiagu    0.72727   1.00000   0.84211         8\n",
      "         Jin    1.00000   0.71429   0.83333         7\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90909   0.88515   0.88171        32\n",
      "weighted avg    0.93182   0.90625   0.90797        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.93333   0.96552        15\n",
      "       Jiagu    0.40000   0.80000   0.53333         5\n",
      "         Jin    0.87500   0.58333   0.70000        12\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.75833   0.77222   0.73295        32\n",
      "weighted avg    0.85938   0.78125   0.79842        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    0.81818   1.00000   0.90000         9\n",
      "         Jin    1.00000   0.84615   0.91667        13\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93939   0.94872   0.93889        32\n",
      "weighted avg    0.94886   0.93750   0.93802        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.90909   1.00000   0.95238        10\n",
      "         Jin    1.00000   0.90000   0.94737        10\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96970   0.96667   0.96658        32\n",
      "weighted avg    0.97159   0.96875   0.96867        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    0.92308   0.80000   0.85714        15\n",
      "         Jin    0.66667   0.85714   0.75000         7\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.86325   0.88571   0.86905        32\n",
      "weighted avg    0.89103   0.87500   0.87835        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92308   0.96000        13\n",
      "       Jiagu    0.91667   0.91667   0.91667        12\n",
      "         Jin    0.75000   0.85714   0.80000         7\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.88889   0.89896   0.89222        32\n",
      "weighted avg    0.91406   0.90625   0.90875        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    1.00000   0.66667   0.80000        12\n",
      "         Jin    0.63636   1.00000   0.77778         7\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87879   0.88889   0.85926        32\n",
      "weighted avg    0.92045   0.87500   0.87639        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.84615   0.91667   0.88000        12\n",
      "       Jiagu    0.83333   0.90909   0.86957        11\n",
      "         Jin    1.00000   0.77778   0.87500         9\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89316   0.86785   0.87486        32\n",
      "weighted avg    0.88502   0.87500   0.87501        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.83333   0.90909         6\n",
      "       Jiagu    0.86667   0.86667   0.86667        15\n",
      "         Jin    0.83333   0.90909   0.86957        11\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.90000   0.86970   0.88177        32\n",
      "weighted avg    0.88021   0.87500   0.87562        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    0.83333   1.00000   0.90909        10\n",
      "         Jin    1.00000   0.85714   0.92308        14\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94444   0.95238   0.94406        32\n",
      "weighted avg    0.94792   0.93750   0.93794        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.88889   0.94118         9\n",
      "       Jiagu    0.61538   1.00000   0.76190         8\n",
      "         Jin    1.00000   0.73333   0.84615        15\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.87179   0.87407   0.84975        32\n",
      "weighted avg    0.90385   0.84375   0.85182        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         2\n",
      "       Jiagu    1.00000   1.00000   1.00000         1\n",
      "         Jin    1.00000   1.00000   1.00000         1\n",
      "\n",
      "    accuracy                        1.00000         4\n",
      "   macro avg    1.00000   1.00000   1.00000         4\n",
      "weighted avg    1.00000   1.00000   1.00000         4\n",
      "\n",
      "{'Accuracy': 1.0, 'F1 Score': 1.0, 'Recall': 1.0}\n",
      "<__main__.AvgrageMeter object at 0x0000026723FF2F10>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d5ad08c89f48099957c9505e25fe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    1.00000   0.83333   0.90909        12\n",
      "         Jin    0.84615   1.00000   0.91667        11\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94872   0.94444   0.94192        32\n",
      "weighted avg    0.94712   0.93750   0.93726        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    1.00000   1.00000   1.00000        11\n",
      "         Jin    1.00000   1.00000   1.00000        10\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   1.00000   0.95652        11\n",
      "       Jiagu    0.90909   0.83333   0.86957        12\n",
      "         Jin    0.88889   0.88889   0.88889         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90488   0.90741   0.90499        32\n",
      "weighted avg    0.90601   0.90625   0.90489        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         9\n",
      "       Jiagu    0.87500   0.63636   0.73684        11\n",
      "         Jin    0.73333   0.91667   0.81481        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.86944   0.85101   0.85055        32\n",
      "weighted avg    0.85703   0.84375   0.84010        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         5\n",
      "       Jiagu    0.77778   0.93333   0.84848        15\n",
      "         Jin    0.88889   0.66667   0.76190        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88889   0.86667   0.87013        32\n",
      "weighted avg    0.85417   0.84375   0.83969        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    0.64286   1.00000   0.78261         9\n",
      "         Jin    1.00000   0.61538   0.76190        13\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88095   0.87179   0.84817        32\n",
      "weighted avg    0.89955   0.84375   0.84213        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    1.00000   1.00000   1.00000         9\n",
      "         Jin    1.00000   1.00000   1.00000        15\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    0.80000   1.00000   0.88889        12\n",
      "         Jin    1.00000   0.66667   0.80000         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93333   0.88889   0.89630        32\n",
      "weighted avg    0.92500   0.90625   0.90208        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         7\n",
      "       Jiagu    0.91667   1.00000   0.95652        11\n",
      "         Jin    1.00000   0.92857   0.96296        14\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97222   0.97619   0.97316        32\n",
      "weighted avg    0.97135   0.96875   0.96885        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        15\n",
      "       Jiagu    1.00000   1.00000   1.00000         8\n",
      "         Jin    1.00000   1.00000   1.00000         9\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    1.00000   1.00000   1.00000         9\n",
      "         Jin    1.00000   1.00000   1.00000         9\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    1.00000   0.77778   0.87500         9\n",
      "         Jin    0.81250   1.00000   0.89655        13\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.93750   0.89259   0.90631        32\n",
      "weighted avg    0.92383   0.90625   0.90637        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90909   0.95238        11\n",
      "       Jiagu    1.00000   1.00000   1.00000        10\n",
      "         Jin    0.91667   1.00000   0.95652        11\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97222   0.96970   0.96963        32\n",
      "weighted avg    0.97135   0.96875   0.96869        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909        10\n",
      "       Jiagu    0.80000   0.80000   0.80000        10\n",
      "         Jin    0.90000   0.75000   0.81818        12\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84444   0.85000   0.84242        32\n",
      "weighted avg    0.84792   0.84375   0.84091        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    1.00000   0.75000   0.85714        12\n",
      "         Jin    0.85714   1.00000   0.92308        12\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91534   0.91667   0.90713        32\n",
      "weighted avg    0.91865   0.90625   0.90288        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.80000   1.00000   0.88889         8\n",
      "       Jiagu    0.92308   0.85714   0.88889        14\n",
      "         Jin    0.88889   0.80000   0.84211        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87066   0.88571   0.87329        32\n",
      "weighted avg    0.88162   0.87500   0.87427        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    1.00000   0.90000   0.94737        10\n",
      "         Jin    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96296   0.96667   0.96285        32\n",
      "weighted avg    0.97222   0.96875   0.96885        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.91667   0.91667        12\n",
      "       Jiagu    0.91667   1.00000   0.95652        11\n",
      "         Jin    1.00000   0.88889   0.94118         9\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94444   0.93519   0.93812        32\n",
      "weighted avg    0.94010   0.93750   0.93726        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.85714   0.92308        14\n",
      "       Jiagu    0.70000   1.00000   0.82353         7\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90000   0.92208   0.89966        32\n",
      "weighted avg    0.93437   0.90625   0.91137        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.83333   1.00000   0.90909        10\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94444   0.93333   0.93266        32\n",
      "weighted avg    0.94792   0.93750   0.93687        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    0.90000   1.00000   0.94737         9\n",
      "         Jin    1.00000   0.88889   0.94118         9\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96667   0.96296   0.96285        32\n",
      "weighted avg    0.97188   0.96875   0.96865        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.88889   0.94118         9\n",
      "       Jiagu    0.82353   1.00000   0.90323        14\n",
      "         Jin    1.00000   0.77778   0.87500         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.94118   0.88889   0.90647        32\n",
      "weighted avg    0.92279   0.90625   0.90596        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92857   0.96296        14\n",
      "       Jiagu    0.90909   0.90909   0.90909        11\n",
      "         Jin    0.87500   1.00000   0.93333         7\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.92803   0.94589   0.93513        32\n",
      "weighted avg    0.94141   0.93750   0.93796        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.81818   1.00000   0.90000         9\n",
      "         Jin    1.00000   0.81818   0.90000        11\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93939   0.93939   0.93333        32\n",
      "weighted avg    0.94886   0.93750   0.93750        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.93333   1.00000   0.96552        14\n",
      "       Jiagu    1.00000   0.66667   0.80000         9\n",
      "         Jin    0.81818   1.00000   0.90000         9\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.91717   0.88889   0.88851        32\n",
      "weighted avg    0.91970   0.90625   0.90054        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.90000   0.90000   0.90000        10\n",
      "         Jin    0.90000   0.90000   0.90000        10\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93333   0.93333   0.93333        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         6\n",
      "       Jiagu    1.00000   1.00000   1.00000        17\n",
      "         Jin    1.00000   1.00000   1.00000         9\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        15\n",
      "       Jiagu    1.00000   1.00000   1.00000         8\n",
      "         Jin    1.00000   1.00000   1.00000         9\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.63636   1.00000   0.77778         7\n",
      "       Jiagu    0.86667   1.00000   0.92857        13\n",
      "         Jin    1.00000   0.50000   0.66667        12\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.83434   0.83333   0.79101        32\n",
      "weighted avg    0.86629   0.81250   0.79737        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.83333   1.00000   0.90909         5\n",
      "       Jiagu    0.57895   1.00000   0.73333        11\n",
      "         Jin    1.00000   0.43750   0.60870        16\n",
      "\n",
      "    accuracy                        0.71875        32\n",
      "   macro avg    0.80409   0.81250   0.75037        32\n",
      "weighted avg    0.82922   0.71875   0.69848        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.90000   1.00000   0.94737         9\n",
      "         Jin    1.00000   0.90909   0.95238        11\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96667   0.96970   0.96658        32\n",
      "weighted avg    0.97188   0.96875   0.96883        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.81818   1.00000   0.90000         9\n",
      "       Jiagu    1.00000   0.90909   0.95238        11\n",
      "         Jin    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93939   0.94192   0.93630        32\n",
      "weighted avg    0.94886   0.93750   0.93920        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    1.00000   0.91667   0.95652        12\n",
      "         Jin    0.88889   1.00000   0.94118         8\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.96296   0.97222   0.96590        32\n",
      "weighted avg    0.97222   0.96875   0.96899        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        10\n",
      "       Jiagu    1.00000   0.87500   0.93333         8\n",
      "         Jin    0.93333   1.00000   0.96552        14\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97778   0.95833   0.96628        32\n",
      "weighted avg    0.97083   0.96875   0.96825        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.90000   0.94737        10\n",
      "       Jiagu    1.00000   0.69231   0.81818        13\n",
      "         Jin    0.64286   1.00000   0.78261         9\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88095   0.86410   0.84939        32\n",
      "weighted avg    0.89955   0.84375   0.84855        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.80000   0.88889        10\n",
      "       Jiagu    0.72727   1.00000   0.84211         8\n",
      "         Jin    0.92308   0.85714   0.88889        14\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88345   0.88571   0.87329        32\n",
      "weighted avg    0.89816   0.87500   0.87719        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000         8\n",
      "       Jiagu    0.93750   1.00000   0.96774        15\n",
      "         Jin    1.00000   0.88889   0.94118         9\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97917   0.96296   0.96964        32\n",
      "weighted avg    0.97070   0.96875   0.96833        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.91667   0.91667   0.91667        12\n",
      "       Jiagu    0.75000   0.90000   0.81818        10\n",
      "         Jin    1.00000   0.80000   0.88889        10\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88889   0.87222   0.87458        32\n",
      "weighted avg    0.89062   0.87500   0.87721        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   0.92857   0.96296        14\n",
      "       Jiagu    0.69231   1.00000   0.81818         9\n",
      "         Jin    1.00000   0.66667   0.80000         9\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.89744   0.86508   0.86038        32\n",
      "weighted avg    0.91346   0.87500   0.87641        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        12\n",
      "       Jiagu    0.84615   1.00000   0.91667        11\n",
      "         Jin    1.00000   0.77778   0.87500         9\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94872   0.92593   0.93056        32\n",
      "weighted avg    0.94712   0.93750   0.93620        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        14\n",
      "       Jiagu    0.81818   1.00000   0.90000         9\n",
      "         Jin    1.00000   0.77778   0.87500         9\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93939   0.92593   0.92500        32\n",
      "weighted avg    0.94886   0.93750   0.93672        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        13\n",
      "       Jiagu    1.00000   0.83333   0.90909        12\n",
      "         Jin    0.77778   1.00000   0.87500         7\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.92593   0.94444   0.92803        32\n",
      "weighted avg    0.95139   0.93750   0.93857        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    0.88889   1.00000   0.94118         8\n",
      "       Jiagu    0.70000   0.70000   0.70000        10\n",
      "         Jin    0.84615   0.78571   0.81481        14\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81168   0.82857   0.81866        32\n",
      "weighted avg    0.81116   0.81250   0.81053        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Xiaozhuan    1.00000   1.00000   1.00000        11\n",
      "       Jiagu    1.00000   1.00000   1.00000        13\n",
      "         Jin    1.00000   1.00000   1.00000         8\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-b5b8815ef220>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train( 1, train_loader, device,net, criterion, optimizer,tensorboard_path) # 完整的训练数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mallacc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensorboard_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#划分80%后的训练数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-139-34c0bc038c52>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, train_loader, device, model, criterion, optimizer, tensorboard_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m# Update metrics here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m               \u001b[1;31m# This function should return a dictionary of metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mtop1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1985\u001b[0m             )\n\u001b[0;32m   1986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1987\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1988\u001b[0m                 \u001b[1;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m                 \u001b[1;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "#train( 1, train_loader, device,net, criterion, optimizer,tensorboard_path) # 完整的训练数据集\n",
    "allacc=train(15, new_train_loader, device,net, criterion, optimizer,tensorboard_path)\n",
    "#划分80%后的训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化训练结果\n",
    "import plotly.graph_objects as go\n",
    "epoch=list(range(1,121))\n",
    "fig = go.Figure(data=go.Scatter(x=epoch, y=allacc, mode='lines+markers'))\n",
    "fig.update_layout(title='准确率随Epoch变化', xaxis_title='Epoch', yaxis_title='准确率')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(net.state_dict(), model_save_path)\n",
    "val_net = MyCNN()\n",
    "val_net.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bbd5319aba4c73a6fca855a0367b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "64.68926553672317"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(validate_loader,device,val_net,criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出测试集预测结果"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "submission(r'C:\\dataset\\guwen_new\\files\\test.csv',test_loader, device, val_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x265d8632df0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
